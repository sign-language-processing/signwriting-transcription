2024-02-21 06:56:58.799129: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-02-21 06:56:58.799182: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-02-21 06:56:58.806651: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-02-21 06:56:58.822776: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-21 06:57:00.837807: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-02-21 06:57:07,488 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2024-02-21 06:57:07,489 - INFO - joeynmt.helpers -                           cfg.name : poses
2024-02-21 06:57:07,489 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2024-02-21 06:57:07,489 - INFO - joeynmt.helpers -                      cfg.data.task : S2T
2024-02-21 06:57:07,489 - INFO - joeynmt.helpers -                     cfg.data.train : vectorized_data_set/poses/train
2024-02-21 06:57:07,489 - INFO - joeynmt.helpers -                       cfg.data.dev : vectorized_data_set/poses/dev
2024-02-21 06:57:07,489 - INFO - joeynmt.helpers -                      cfg.data.test : vectorized_data_set/poses/test
2024-02-21 06:57:07,489 - INFO - joeynmt.helpers -              cfg.data.dataset_type : speech
2024-02-21 06:57:07,489 - INFO - joeynmt.helpers -                  cfg.data.src.lang : en_ng
2024-02-21 06:57:07,489 - INFO - joeynmt.helpers -              cfg.data.src.num_freq : 534
2024-02-21 06:57:07,489 - INFO - joeynmt.helpers -            cfg.data.src.max_length : 3000
2024-02-21 06:57:07,489 - INFO - joeynmt.helpers -            cfg.data.src.min_length : 1
2024-02-21 06:57:07,489 - INFO - joeynmt.helpers -                 cfg.data.src.level : frame
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : pose
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers -               cfg.data.src.augment : True
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers -             cfg.data.src.aug_param : 0.2
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers -                 cfg.data.src.noise : False
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers -           cfg.data.src.noise_param : 0
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.specaugment.freq_mask_n : 1
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.specaugment.freq_mask_f : 5
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.specaugment.time_mask_n : 1
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.specaugment.time_mask_t : 10
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.specaugment.time_mask_p : 1.0
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.cmvn.norm_means : True
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.cmvn.norm_vars : True
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.cmvn.before : True
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : en_ng
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers -            cfg.data.trg.max_length : 100
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers -                 cfg.data.trg.level : vpf
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : vectorized_data_set/poses/spm_bpe1182.vocab
2024-02-21 06:57:07,490 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : pose-vpf
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.model_file : vectorized_data_set/poses/spm_bpe1182.model
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenize : none
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -       cfg.testing.eval_all_metrics : False
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -                 cfg.testing.n_best : 1
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -             cfg.testing.beam_alpha : 1.0
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -             cfg.testing.batch_size : 4
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -             cfg.testing.batch_type : sentence
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -      cfg.testing.max_output_length : 100
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers - cfg.testing.sacrebleu_cfg.tokenize : intl
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -            cfg.training.adam_betas : [0.9, 0.98]
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -              cfg.training.patience : 5
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0002
2024-02-21 06:57:07,491 - INFO - joeynmt.helpers -     cfg.training.learning_rate_min : 1e-08
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.1
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -                  cfg.training.loss : crossentropy-ctc
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -            cfg.training.ctc_weight : 0.3
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -            cfg.training.batch_size : 4
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -            cfg.training.batch_type : sentence
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -      cfg.training.batch_multiplier : 1
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : chrf
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -                cfg.training.epochs : 15
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 1000
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -             cfg.training.model_dir : experiment
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -             cfg.training.overwrite : True
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3]
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -       cfg.training.keep_best_ckpts : 2
2024-02-21 06:57:07,492 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : False
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : False
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 12
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 4
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 534
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 1024
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0.1
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -       cfg.model.encoder.layer_norm : pre
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -        cfg.model.encoder.subsample : True
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers - cfg.model.encoder.conv_kernel_sizes : [5, 5]
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -    cfg.model.encoder.conv_channels : 512
2024-02-21 06:57:07,493 - INFO - joeynmt.helpers -      cfg.model.encoder.in_channels : 534
2024-02-21 06:57:07,494 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2024-02-21 06:57:07,494 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 6
2024-02-21 06:57:07,494 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 4
2024-02-21 06:57:07,494 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2024-02-21 06:57:07,494 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2024-02-21 06:57:07,494 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.0
2024-02-21 06:57:07,494 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2024-02-21 06:57:07,494 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 1024
2024-02-21 06:57:07,494 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0.1
2024-02-21 06:57:07,494 - INFO - joeynmt.helpers -       cfg.model.decoder.layer_norm : pre
2024-02-21 06:57:07,569 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.data - Building tokenizer...
2024-02-21 06:57:07,570 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.tokenizer - src Tokenizer: PoseProcessor(level=frame, normalize=False, filter_by_length=(1, 3000),
2024-02-21 06:57:07,570 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.tokenizer - trg Tokenizer: SwuTokenizer(level=vpf, lowercase=False, normalize=False, filter_by_length=(-1, 100), pretokenizer=none, tokenizer=SignWritingTokenizer)
2024-02-21 06:57:07,570 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.data - Loading train set...
2024-02-21 06:57:07,889 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.data - Building vocabulary...
2024-02-21 06:57:07,900 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.data - Loading dev set...
2024-02-21 06:57:07,915 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.data - Loading test set...
2024-02-21 06:57:07,927 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.data - Data loaded.
2024-02-21 06:57:07,927 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.data - Train dataset: SpeechDataset(split=train, len=15918, src_lang=src, trg_lang=trg, has_trg=True, random_subset=-1)
2024-02-21 06:57:07,927 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.data - Valid dataset: SpeechDataset(split=dev, len=346, src_lang=src, trg_lang=trg, has_trg=True, random_subset=-1)
2024-02-21 06:57:07,927 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.data -  Test dataset: SpeechDataset(split=test, len=247, src_lang=src, trg_lang=trg, has_trg=True, random_subset=-1)
2024-02-21 06:57:07,928 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.data - First training example:
	[TRG] M p500 p500 S2ff c0 r0 p476 p458 S33b c1 r0 p487 p482 S171 c1 r7 p510 p502 S22e c0 r2 p494 p525
2024-02-21 06:57:07,929 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) B (5) L (6) M (7) R (8) S100 (9) S101
2024-02-21 06:57:07,929 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.data - Number of unique Trg tokens (vocab_size): 1182
2024-02-21 06:57:07,929 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-02-21 06:57:08,347 - INFO - joeynmt.model - Enc-dec model built.
2024-02-21 06:57:08,356 - INFO - joeynmt.model - Total params: 18729984
2024-02-21 06:57:08,359 - INFO - joeynmt.training - Model(task=S2T,
	encoder=TransformerEncoder(num_layers=12, num_heads=4, alpha=1.0, layer_norm="pre", subsample=True),
	decoder=TransformerDecoder(num_layers=6, num_heads=4, alpha=1.0, layer_norm="pre", ctc_layer=True),
	src_embed=Identity(),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=1182),
	loss_function=XentCTCLoss(criterion=KLDivLoss(), smoothing=0.1, ctc=CTCLoss(), ctc_weight=0.3))
2024-02-21 06:57:09,067 - INFO - joeynmt.builders - Adam(lr=0.0002, weight_decay=0.0, betas=[0.9, 0.98])
2024-02-21 06:57:09,067 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=max, verbose=False, threshold_mode=abs, eps=0.0, factor=0.1, patience=5)
2024-02-21 06:57:09,067 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 4
	effective batch size (w. parallel & accumulation): 4
2024-02-21 06:57:09,067 - INFO - joeynmt.training - EPOCH 1
2024-02-21 06:58:02,442 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.318579, Batch Acc: 0.244141, Tokens per Sec:      320, Lr: 0.000200
2024-02-21 06:59:12,506 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     2.166860, Batch Acc: 0.326461, Tokens per Sec:      240, Lr: 0.000200
2024-02-21 07:00:03,449 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     2.010263, Batch Acc: 0.327003, Tokens per Sec:      337, Lr: 0.000200
2024-02-21 07:00:55,665 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     2.373163, Batch Acc: 0.337599, Tokens per Sec:      316, Lr: 0.000200
2024-02-21 07:01:46,334 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     2.120009, Batch Acc: 0.336257, Tokens per Sec:      337, Lr: 0.000200
2024-02-21 07:02:37,223 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     1.932554, Batch Acc: 0.336421, Tokens per Sec:      342, Lr: 0.000200
2024-02-21 07:03:26,217 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     2.695385, Batch Acc: 0.340426, Tokens per Sec:      341, Lr: 0.000200
2024-02-21 07:04:16,575 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     1.826734, Batch Acc: 0.340323, Tokens per Sec:      332, Lr: 0.000200
2024-02-21 07:05:07,065 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     2.034809, Batch Acc: 0.344686, Tokens per Sec:      334, Lr: 0.000200
2024-02-21 07:05:57,049 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     2.168966, Batch Acc: 0.355126, Tokens per Sec:      342, Lr: 0.000200
2024-02-21 07:05:57,049 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:42<00:00,  8.11it/s]
2024-02-21 07:06:40,351 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  30.38, loss:   1.94, ppl:   6.94, acc:   0.35, generation: 42.6899[sec], evaluation: 0.5891[sec]
2024-02-21 07:06:40,352 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 07:06:44,630 - INFO - joeynmt.training - Example #0
2024-02-21 07:06:44,631 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 07:06:44,631 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 07:06:44,631 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x443S2ff00495x443S35d10452x467S10050461x510S2f900461x510S2f900495x510S2f900461x510S2f900457x510
2024-02-21 07:06:44,631 - INFO - joeynmt.training - Example #1
2024-02-21 07:06:44,632 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 07:06:44,633 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 07:06:44,633 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x443S2ff00495x443S2ff00443x443S35d14456x476S2f900451x496S2f900534x493S2f900443x510S2f900457x510S2f900p534S2f900p534S2f900p534
2024-02-21 07:06:44,633 - INFO - joeynmt.training - Example #2
2024-02-21 07:06:44,633 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 07:06:44,633 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 07:06:44,633 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x443S2ff00482x443S2ff00443x443S35d10452x476S2f900452x496S2f900452x496S2f900443x510S2f900452x496S2f900p534
2024-02-21 07:06:44,633 - INFO - joeynmt.training - Example #3
2024-02-21 07:06:44,634 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 07:06:44,634 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 07:06:44,634 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x443S2ff00495x443S35d10452x476S15a50461x510S2f900510x510S2f900495x510S2f900534x510
2024-02-21 07:07:34,701 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     2.202946, Batch Acc: 0.351726, Tokens per Sec:      317, Lr: 0.000200
2024-02-21 07:08:24,516 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     1.959051, Batch Acc: 0.364087, Tokens per Sec:      328, Lr: 0.000200
2024-02-21 07:09:13,972 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     1.653398, Batch Acc: 0.355857, Tokens per Sec:      353, Lr: 0.000200
2024-02-21 07:10:04,839 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     1.832919, Batch Acc: 0.352261, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 07:10:53,199 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     1.887974, Batch Acc: 0.363679, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 07:11:42,756 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     1.711824, Batch Acc: 0.369435, Tokens per Sec:      339, Lr: 0.000200
2024-02-21 07:12:32,107 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     1.719798, Batch Acc: 0.371762, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 07:13:21,440 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     1.725309, Batch Acc: 0.367707, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 07:14:11,756 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     1.586362, Batch Acc: 0.371313, Tokens per Sec:      344, Lr: 0.000200
2024-02-21 07:15:00,363 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.000595, Batch Acc: 0.380909, Tokens per Sec:      339, Lr: 0.000200
2024-02-21 07:15:00,363 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:27<00:00, 12.51it/s]
2024-02-21 07:15:28,447 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  29.42, loss:   1.84, ppl:   6.30, acc:   0.37, generation: 27.6684[sec], evaluation: 0.3965[sec]
2024-02-21 07:15:28,448 - INFO - joeynmt.training - Example #0
2024-02-21 07:15:28,449 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 07:15:28,449 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 07:15:28,449 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x451S35d10495x479S15a50495x495S15a50495x495S20500495x495S20500495x513
2024-02-21 07:15:28,449 - INFO - joeynmt.training - Example #1
2024-02-21 07:15:28,450 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 07:15:28,450 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 07:15:28,450 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x451S35d10495x479S15a10495x495S15a18476x513S2f900495x513S2f900479x513
2024-02-21 07:15:28,450 - INFO - joeynmt.training - Example #2
2024-02-21 07:15:28,450 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 07:15:28,450 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 07:15:28,451 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x457S35d10495x479S15a10495x495S2f900479x513
2024-02-21 07:15:28,451 - INFO - joeynmt.training - Example #3
2024-02-21 07:15:28,451 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 07:15:28,451 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 07:15:28,451 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x457S35d10495x479S15a10495x497
2024-02-21 07:16:17,784 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     1.654344, Batch Acc: 0.372727, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 07:17:05,505 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.358786, Batch Acc: 0.378813, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 07:17:55,247 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     1.848166, Batch Acc: 0.379669, Tokens per Sec:      330, Lr: 0.000200
2024-02-21 07:18:44,775 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     1.806833, Batch Acc: 0.379092, Tokens per Sec:      348, Lr: 0.000200
2024-02-21 07:19:33,957 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     1.892504, Batch Acc: 0.379010, Tokens per Sec:      341, Lr: 0.000200
2024-02-21 07:20:23,071 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     1.836755, Batch Acc: 0.382979, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 07:21:12,607 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.134094, Batch Acc: 0.376929, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 07:22:01,089 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     1.766017, Batch Acc: 0.387661, Tokens per Sec:      353, Lr: 0.000200
2024-02-21 07:22:50,239 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     1.704058, Batch Acc: 0.388869, Tokens per Sec:      335, Lr: 0.000200
2024-02-21 07:23:39,141 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     1.845397, Batch Acc: 0.383230, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 07:23:39,141 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:26<00:00, 13.02it/s]
2024-02-21 07:24:06,094 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  28.27, loss:   1.77, ppl:   5.88, acc:   0.38, generation: 26.5709[sec], evaluation: 0.3648[sec]
2024-02-21 07:24:06,095 - INFO - joeynmt.training - Example #0
2024-02-21 07:24:06,096 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 07:24:06,096 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 07:24:06,096 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x441S35d14495x459S20350495x495S20358483x495S26606503x495S26606503x514S2fb04492x552
2024-02-21 07:24:06,096 - INFO - joeynmt.training - Example #1
2024-02-21 07:24:06,097 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 07:24:06,097 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 07:24:06,097 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x439S35d14495x459S15a49473x510S2f900495x538S2f900495x537S20500495x519
2024-02-21 07:24:06,097 - INFO - joeynmt.training - Example #2
2024-02-21 07:24:06,098 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 07:24:06,098 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 07:24:06,098 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x439S35d14495x463S1ce10495x483S2f900495x537
2024-02-21 07:24:06,098 - INFO - joeynmt.training - Example #3
2024-02-21 07:24:06,098 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 07:24:06,098 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 07:24:06,098 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x483S35d14493x490
2024-02-21 07:24:56,098 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     1.564565, Batch Acc: 0.388373, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 07:25:45,217 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     1.938089, Batch Acc: 0.386554, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 07:26:32,998 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     1.711172, Batch Acc: 0.393929, Tokens per Sec:      369, Lr: 0.000200
2024-02-21 07:27:21,642 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     1.591533, Batch Acc: 0.389666, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 07:28:10,256 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     1.697685, Batch Acc: 0.395207, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 07:29:00,289 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     1.837652, Batch Acc: 0.398321, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 07:29:48,633 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     1.585938, Batch Acc: 0.390310, Tokens per Sec:      374, Lr: 0.000200
2024-02-21 07:30:36,530 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     1.531542, Batch Acc: 0.408827, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 07:31:25,440 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     1.403594, Batch Acc: 0.404625, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 07:31:44,257 - INFO - joeynmt.training - Epoch   1: total training loss 7453.54, num seqs 15756, num tokens 672796
2024-02-21 07:31:44,257 - INFO - joeynmt.training - EPOCH 2
2024-02-21 07:32:14,084 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     1.421656, Batch Acc: 0.404696, Tokens per Sec:      361, Lr: 0.000200
2024-02-21 07:32:14,084 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:36<00:00,  9.45it/s]
2024-02-21 07:32:51,224 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  37.79, loss:   1.71, ppl:   5.53, acc:   0.40, generation: 36.6086[sec], evaluation: 0.5115[sec]
2024-02-21 07:32:51,225 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 07:32:51,818 - INFO - joeynmt.training - Example #0
2024-02-21 07:32:51,820 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 07:32:51,820 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 07:32:51,820 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x459S15a50495x503S15a58478x512S2f900479x538S20500495x515S20500495x522
2024-02-21 07:32:51,820 - INFO - joeynmt.training - Example #1
2024-02-21 07:32:51,821 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 07:32:51,821 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 07:32:51,821 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x459S15a1a478x510S15a1a478x510S2f900479x538S2f900495x538S15a0a502x515
2024-02-21 07:32:51,821 - INFO - joeynmt.training - Example #2
2024-02-21 07:32:51,821 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 07:32:51,822 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 07:32:51,822 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x458S16d10495x497S16d18478x497S2f900468x538
2024-02-21 07:32:51,822 - INFO - joeynmt.training - Example #3
2024-02-21 07:32:51,822 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 07:32:51,822 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 07:32:51,822 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x454S35d14495x458S15a10495x503S15a10495x502
2024-02-21 07:33:40,340 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     1.632483, Batch Acc: 0.402785, Tokens per Sec:      358, Lr: 0.000200
2024-02-21 07:34:28,390 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     1.670444, Batch Acc: 0.400631, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 07:35:16,937 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     1.432703, Batch Acc: 0.406327, Tokens per Sec:      351, Lr: 0.000200
2024-02-21 07:36:05,867 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     1.521037, Batch Acc: 0.410133, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 07:36:55,185 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     1.502157, Batch Acc: 0.417525, Tokens per Sec:      331, Lr: 0.000200
2024-02-21 07:37:42,289 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     1.647121, Batch Acc: 0.413028, Tokens per Sec:      370, Lr: 0.000200
2024-02-21 07:38:30,866 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     1.623365, Batch Acc: 0.409284, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 07:39:19,706 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     1.628232, Batch Acc: 0.413945, Tokens per Sec:      340, Lr: 0.000200
2024-02-21 07:40:10,000 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     1.770789, Batch Acc: 0.406979, Tokens per Sec:      338, Lr: 0.000200
2024-02-21 07:40:58,400 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     1.905196, Batch Acc: 0.411443, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 07:40:58,401 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:37<00:00,  9.15it/s]
2024-02-21 07:41:37,124 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  37.24, loss:   1.67, ppl:   5.31, acc:   0.41, generation: 37.8073[sec], evaluation: 0.8801[sec]
2024-02-21 07:41:42,176 - INFO - joeynmt.helpers - delete experiment/1000.ckpt
2024-02-21 07:41:42,218 - INFO - joeynmt.training - Example #0
2024-02-21 07:41:42,220 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 07:41:42,220 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 07:41:42,220 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x439S35d10495x461S20350495x483S20358476x483S20350510x483S20500495x494S26606510x510S26612467x510S2fb04492x554
2024-02-21 07:41:42,220 - INFO - joeynmt.training - Example #1
2024-02-21 07:41:42,221 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 07:41:42,221 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 07:41:42,221 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x457S15a1a480x492S2f900495x535S2f900495x539S2f900495x539S2f900495x539
2024-02-21 07:41:42,221 - INFO - joeynmt.training - Example #2
2024-02-21 07:41:42,222 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 07:41:42,222 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 07:41:42,222 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x446S35d10495x461S14c10501x477S14c18470x494S14c10510x480S20500495x510S2fb04492x559
2024-02-21 07:41:42,222 - INFO - joeynmt.training - Example #3
2024-02-21 07:41:42,222 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 07:41:42,222 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 07:41:42,223 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x457S35d10495x477S15a10510x510S20500495x510
2024-02-21 07:42:31,668 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     1.542845, Batch Acc: 0.413353, Tokens per Sec:      319, Lr: 0.000200
2024-02-21 07:43:20,358 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     1.551661, Batch Acc: 0.403343, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 07:44:09,615 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     1.810342, Batch Acc: 0.416213, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 07:44:58,737 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     1.662864, Batch Acc: 0.415671, Tokens per Sec:      361, Lr: 0.000200
2024-02-21 07:45:47,641 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     1.916611, Batch Acc: 0.412223, Tokens per Sec:      341, Lr: 0.000200
2024-02-21 07:46:37,590 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     1.932309, Batch Acc: 0.417649, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 07:47:26,331 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     1.480684, Batch Acc: 0.422637, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 07:48:15,641 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     1.661214, Batch Acc: 0.414797, Tokens per Sec:      337, Lr: 0.000200
2024-02-21 07:49:04,551 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     1.360155, Batch Acc: 0.427367, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 07:49:53,833 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     1.785069, Batch Acc: 0.421738, Tokens per Sec:      340, Lr: 0.000200
2024-02-21 07:49:53,833 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:35<00:00,  9.66it/s]
2024-02-21 07:50:30,199 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  38.40, loss:   1.64, ppl:   5.17, acc:   0.42, generation: 35.8047[sec], evaluation: 0.5410[sec]
2024-02-21 07:50:30,200 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 07:50:30,793 - INFO - joeynmt.helpers - delete experiment/5000.ckpt
2024-02-21 07:50:30,838 - INFO - joeynmt.training - Example #0
2024-02-21 07:50:30,839 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 07:50:30,839 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 07:50:30,839 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x439S35d14495x456S14c50503x483S14c58473x483S26606507x506S26612473x516S2fb04493x555
2024-02-21 07:50:30,839 - INFO - joeynmt.training - Example #1
2024-02-21 07:50:30,840 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 07:50:30,840 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 07:50:30,840 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x439S35d14495x460S15a18477x506S15a18476x506S2f900477x538S20500495x519S20500495x519
2024-02-21 07:50:30,840 - INFO - joeynmt.training - Example #2
2024-02-21 07:50:30,840 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 07:50:30,840 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 07:50:30,841 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00449x449S2ff00517x456S35d14456x477S15a18443x506S2f900439x538S2f900439x538S15a10449x505S20500456x503S20500456x494
2024-02-21 07:50:30,841 - INFO - joeynmt.training - Example #3
2024-02-21 07:50:30,842 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 07:50:30,842 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 07:50:30,842 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00473x456S35d14491x479S15a10488x505S20500488x496
2024-02-21 07:51:21,157 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     1.657698, Batch Acc: 0.416178, Tokens per Sec:      344, Lr: 0.000200
2024-02-21 07:52:09,274 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     1.552270, Batch Acc: 0.426101, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 07:52:57,659 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     1.694392, Batch Acc: 0.428854, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 07:53:46,213 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     1.630653, Batch Acc: 0.421724, Tokens per Sec:      349, Lr: 0.000200
2024-02-21 07:54:35,127 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     1.477646, Batch Acc: 0.421565, Tokens per Sec:      342, Lr: 0.000200
2024-02-21 07:55:26,474 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     1.464842, Batch Acc: 0.423931, Tokens per Sec:      335, Lr: 0.000200
2024-02-21 07:56:14,477 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     1.964030, Batch Acc: 0.433615, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 07:57:02,985 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     1.744937, Batch Acc: 0.441447, Tokens per Sec:      325, Lr: 0.000200
2024-02-21 07:57:51,847 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     1.662815, Batch Acc: 0.428954, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 07:58:40,465 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     1.482441, Batch Acc: 0.431111, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 07:58:40,466 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:53<00:00,  6.50it/s]
2024-02-21 07:59:34,399 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  38.45, loss:   1.61, ppl:   5.01, acc:   0.43, generation: 53.2055[sec], evaluation: 0.7049[sec]
2024-02-21 07:59:34,400 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 07:59:34,978 - INFO - joeynmt.helpers - delete experiment/4000.ckpt
2024-02-21 07:59:35,020 - INFO - joeynmt.training - Example #0
2024-02-21 07:59:35,021 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 07:59:35,021 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 07:59:35,022 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x441S35d14495x459S14c50501x482S14c58470x482S20500495x508S20500495x508S20500495x508S20500495x508S20500495x508S26606514x514S26612464x514
2024-02-21 07:59:35,022 - INFO - joeynmt.training - Example #1
2024-02-21 07:59:35,022 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 07:59:35,022 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 07:59:35,022 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04493x560S22f02508x508S22f12467x508S22f02464x508S22f16467x508
2024-02-21 07:59:35,022 - INFO - joeynmt.training - Example #2
2024-02-21 07:59:35,023 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 07:59:35,023 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 07:59:35,023 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x436S2ff00508x436S35010453x459S14c10459x475S14c18436x477S2f900437x525S20500448x508S20500448x494S20500448x494S20500456x494S20500540x477S2df08515x494S2df1c523x508S2fb04540x561
2024-02-21 07:59:35,023 - INFO - joeynmt.training - Example #3
2024-02-21 07:59:35,024 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 07:59:35,024 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 07:59:35,024 - INFO - joeynmt.training - 	Hypothesis: M500x500S30004482x464S35010495x488S10002501x496S20500495x496
2024-02-21 08:00:24,192 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     1.375412, Batch Acc: 0.434224, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 08:01:13,030 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     1.626840, Batch Acc: 0.434132, Tokens per Sec:      355, Lr: 0.000200
2024-02-21 08:02:00,905 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     1.386424, Batch Acc: 0.433463, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 08:02:50,809 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     1.567254, Batch Acc: 0.427758, Tokens per Sec:      334, Lr: 0.000200
2024-02-21 08:03:39,633 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     1.325319, Batch Acc: 0.436039, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 08:04:28,639 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     1.439789, Batch Acc: 0.432723, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 08:05:16,261 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     1.373609, Batch Acc: 0.435497, Tokens per Sec:      358, Lr: 0.000200
2024-02-21 08:06:04,817 - INFO - joeynmt.training - Epoch   2, Step:     7800, Batch Loss:     1.902717, Batch Acc: 0.432820, Tokens per Sec:      361, Lr: 0.000200
2024-02-21 08:06:43,549 - INFO - joeynmt.training - Epoch   2: total training loss 6464.67, num seqs 15756, num tokens 672796
2024-02-21 08:06:43,549 - INFO - joeynmt.training - EPOCH 3
2024-02-21 08:06:54,497 - INFO - joeynmt.training - Epoch   3, Step:     7900, Batch Loss:     1.450918, Batch Acc: 0.448092, Tokens per Sec:      342, Lr: 0.000200
2024-02-21 08:07:43,639 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:     1.664374, Batch Acc: 0.441261, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 08:07:43,640 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:46<00:00,  7.49it/s]
2024-02-21 08:08:30,953 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  40.57, loss:   1.58, ppl:   4.87, acc:   0.44, generation: 46.1815[sec], evaluation: 1.0904[sec]
2024-02-21 08:08:30,954 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 08:08:36,318 - INFO - joeynmt.helpers - delete experiment/6000.ckpt
2024-02-21 08:08:36,359 - INFO - joeynmt.training - Example #0
2024-02-21 08:08:36,360 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 08:08:36,360 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 08:08:36,360 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x439S35d14495x458S14c50501x479S14c58469x479S26606508x508S26612464x508S26606508x508S26612458x512S2fb04492x560
2024-02-21 08:08:36,361 - INFO - joeynmt.training - Example #1
2024-02-21 08:08:36,361 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 08:08:36,361 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 08:08:36,361 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S20306479x481S20306489x507S2030e502x507S23600508x508S23610458x507S2fd04492x560
2024-02-21 08:08:36,361 - INFO - joeynmt.training - Example #2
2024-02-21 08:08:36,362 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 08:08:36,362 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 08:08:36,362 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00438x450S2ff00507x458S35d14456x478S15a18502x507S2f900508x538S20500525x525S2f900511x525S22a02537x525S15a18508x519S15a10532x507S2f900513x525
2024-02-21 08:08:36,362 - INFO - joeynmt.training - Example #3
2024-02-21 08:08:36,363 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 08:08:36,363 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 08:08:36,363 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00475x459S35d14488x479S20300507x507S26500507x507
2024-02-21 08:09:25,597 - INFO - joeynmt.training - Epoch   3, Step:     8100, Batch Loss:     1.441112, Batch Acc: 0.440114, Tokens per Sec:      320, Lr: 0.000200
2024-02-21 08:10:15,447 - INFO - joeynmt.training - Epoch   3, Step:     8200, Batch Loss:     1.790930, Batch Acc: 0.450176, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 08:11:03,017 - INFO - joeynmt.training - Epoch   3, Step:     8300, Batch Loss:     1.558897, Batch Acc: 0.442785, Tokens per Sec:      374, Lr: 0.000200
2024-02-21 08:11:51,626 - INFO - joeynmt.training - Epoch   3, Step:     8400, Batch Loss:     1.355796, Batch Acc: 0.445290, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 08:12:40,155 - INFO - joeynmt.training - Epoch   3, Step:     8500, Batch Loss:     1.203071, Batch Acc: 0.450917, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 08:13:28,802 - INFO - joeynmt.training - Epoch   3, Step:     8600, Batch Loss:     1.497548, Batch Acc: 0.452542, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 08:14:17,715 - INFO - joeynmt.training - Epoch   3, Step:     8700, Batch Loss:     1.507608, Batch Acc: 0.443874, Tokens per Sec:      355, Lr: 0.000200
2024-02-21 08:15:05,800 - INFO - joeynmt.training - Epoch   3, Step:     8800, Batch Loss:     1.436395, Batch Acc: 0.449772, Tokens per Sec:      351, Lr: 0.000200
2024-02-21 08:15:54,145 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     1.543608, Batch Acc: 0.444892, Tokens per Sec:      344, Lr: 0.000200
2024-02-21 08:16:43,173 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     1.166210, Batch Acc: 0.451366, Tokens per Sec:      355, Lr: 0.000200
2024-02-21 08:16:43,173 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:51<00:00,  6.67it/s]
2024-02-21 08:17:35,757 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  40.28, loss:   1.56, ppl:   4.74, acc:   0.44, generation: 51.8606[sec], evaluation: 0.6959[sec]
2024-02-21 08:17:40,816 - INFO - joeynmt.helpers - delete experiment/7000.ckpt
2024-02-21 08:17:40,857 - INFO - joeynmt.training - Example #0
2024-02-21 08:17:40,859 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 08:17:40,859 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 08:17:40,859 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x560S14c50501x483S14c58472x483S22520503x476S22520503x476S22520503x476S22520476x476S22520469x476S22520469x476S22520463x476S22520463x476S22520463x484
2024-02-21 08:17:40,859 - INFO - joeynmt.training - Example #1
2024-02-21 08:17:40,860 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 08:17:40,860 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 08:17:40,860 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S20500495x473S2fb04492x560S20500495x477S20500495x479S20500495x479S20500495x479
2024-02-21 08:17:40,860 - INFO - joeynmt.training - Example #2
2024-02-21 08:17:40,860 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 08:17:40,860 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 08:17:40,860 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00446x446S2ff00517x457S35d14457x477S15a18443x494S2f900443x531S2f900511x531S16d10540x497S22a02540x517S10002540x516S10000540x499
2024-02-21 08:17:40,860 - INFO - joeynmt.training - Example #3
2024-02-21 08:17:40,861 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 08:17:40,861 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 08:17:40,861 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00479x457S35d14490x479S20310502x500S20310494x500S22a04502x517
2024-02-21 08:18:29,773 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     1.366854, Batch Acc: 0.450228, Tokens per Sec:      317, Lr: 0.000200
2024-02-21 08:19:19,344 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     1.264292, Batch Acc: 0.445955, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 08:20:08,331 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     1.221975, Batch Acc: 0.453341, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 08:20:56,019 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     1.461548, Batch Acc: 0.446732, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 08:21:46,053 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     1.435718, Batch Acc: 0.450059, Tokens per Sec:      340, Lr: 0.000200
2024-02-21 08:22:35,042 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     1.411978, Batch Acc: 0.457177, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 08:23:24,132 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     1.787296, Batch Acc: 0.444984, Tokens per Sec:      353, Lr: 0.000200
2024-02-21 08:24:12,379 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     1.502732, Batch Acc: 0.445711, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 08:25:01,243 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     1.652920, Batch Acc: 0.455075, Tokens per Sec:      348, Lr: 0.000200
2024-02-21 08:25:49,505 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     1.486799, Batch Acc: 0.456912, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 08:25:49,506 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:52<00:00,  6.56it/s]
2024-02-21 08:26:42,989 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  41.39, loss:   1.54, ppl:   4.66, acc:   0.45, generation: 52.7701[sec], evaluation: 0.6893[sec]
2024-02-21 08:26:42,990 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 08:26:43,824 - INFO - joeynmt.helpers - delete experiment/9000.ckpt
2024-02-21 08:26:43,865 - INFO - joeynmt.training - Example #0
2024-02-21 08:26:43,866 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 08:26:43,866 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 08:26:43,866 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x439S35d14495x459S20350501x483S20358476x482S26606504x493S26612457x482S26616457x511S2fb04492x551
2024-02-21 08:26:43,867 - INFO - joeynmt.training - Example #1
2024-02-21 08:26:43,867 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 08:26:43,867 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 08:26:43,867 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x439S35d14495x459S10002500x483S1000a477x493S2ea00504x512S2ea4c477x511S2fd04489x551
2024-02-21 08:26:43,867 - INFO - joeynmt.training - Example #2
2024-02-21 08:26:43,868 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 08:26:43,868 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 08:26:43,868 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x453S30004521x453S35d10453x477S10010459x494S10018446x494S20500453x494S20500453x494S20500453x494S26a04460x520S26a14448x520S2fb04455x547
2024-02-21 08:26:43,868 - INFO - joeynmt.training - Example #3
2024-02-21 08:26:43,868 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 08:26:43,869 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 08:26:43,869 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00474x459S35d10487x481S10010498x494S20500495x497
2024-02-21 08:27:32,468 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     1.628196, Batch Acc: 0.454324, Tokens per Sec:      340, Lr: 0.000200
2024-02-21 08:28:21,662 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     1.180172, Batch Acc: 0.454163, Tokens per Sec:      358, Lr: 0.000200
2024-02-21 08:29:11,314 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     1.467540, Batch Acc: 0.460299, Tokens per Sec:      336, Lr: 0.000200
2024-02-21 08:29:59,369 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     1.382920, Batch Acc: 0.451164, Tokens per Sec:      351, Lr: 0.000200
2024-02-21 08:30:46,880 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     1.313355, Batch Acc: 0.450910, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 08:31:34,969 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     1.762648, Batch Acc: 0.457842, Tokens per Sec:      340, Lr: 0.000200
2024-02-21 08:32:25,169 - INFO - joeynmt.training - Epoch   3, Step:    10700, Batch Loss:     1.376510, Batch Acc: 0.460063, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 08:33:13,159 - INFO - joeynmt.training - Epoch   3, Step:    10800, Batch Loss:     1.409838, Batch Acc: 0.460752, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 08:34:00,822 - INFO - joeynmt.training - Epoch   3, Step:    10900, Batch Loss:     1.676862, Batch Acc: 0.456536, Tokens per Sec:      361, Lr: 0.000200
2024-02-21 08:34:48,999 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     1.500854, Batch Acc: 0.454190, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 08:34:48,999 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:43<00:00,  8.00it/s]
2024-02-21 08:35:32,896 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  39.55, loss:   1.52, ppl:   4.57, acc:   0.45, generation: 43.2349[sec], evaluation: 0.6397[sec]
2024-02-21 08:35:32,898 - INFO - joeynmt.training - Example #0
2024-02-21 08:35:32,899 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 08:35:32,899 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 08:35:32,899 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x441S35d14495x461S1dc50501x489S1dc58476x484S20500495x484S2fb04492x554S26606506x517S26612467x517
2024-02-21 08:35:32,899 - INFO - joeynmt.training - Example #1
2024-02-21 08:35:32,900 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 08:35:32,900 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 08:35:32,900 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x441S35d14495x461S1ea0e501x482S1ea06477x482S1ea0e477x482S1ea06477x482S1ea0e477x482S2fb04492x554
2024-02-21 08:35:32,900 - INFO - joeynmt.training - Example #2
2024-02-21 08:35:32,901 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 08:35:32,901 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 08:35:32,901 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x436S2ff00513x436S35d14456x456S18510462x477S18518436x477S18510456x481S18518505x481S2fc04523x554S18510462x477S26a04456x505
2024-02-21 08:35:32,901 - INFO - joeynmt.training - Example #3
2024-02-21 08:35:32,902 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 08:35:32,902 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 08:35:32,902 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x457S35d14495x477S10000501x498S22b04505x505
2024-02-21 08:36:22,293 - INFO - joeynmt.training - Epoch   3, Step:    11100, Batch Loss:     1.468361, Batch Acc: 0.454647, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 08:37:10,686 - INFO - joeynmt.training - Epoch   3, Step:    11200, Batch Loss:     1.830354, Batch Acc: 0.462254, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 08:37:59,069 - INFO - joeynmt.training - Epoch   3, Step:    11300, Batch Loss:     1.901079, Batch Acc: 0.455370, Tokens per Sec:      348, Lr: 0.000200
2024-02-21 08:38:46,145 - INFO - joeynmt.training - Epoch   3, Step:    11400, Batch Loss:     1.441264, Batch Acc: 0.466198, Tokens per Sec:      365, Lr: 0.000200
2024-02-21 08:39:35,856 - INFO - joeynmt.training - Epoch   3, Step:    11500, Batch Loss:     1.469357, Batch Acc: 0.458997, Tokens per Sec:      355, Lr: 0.000200
2024-02-21 08:40:23,852 - INFO - joeynmt.training - Epoch   3, Step:    11600, Batch Loss:     1.639342, Batch Acc: 0.458333, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 08:41:11,585 - INFO - joeynmt.training - Epoch   3, Step:    11700, Batch Loss:     1.541341, Batch Acc: 0.461357, Tokens per Sec:      374, Lr: 0.000200
2024-02-21 08:41:58,982 - INFO - joeynmt.training - Epoch   3, Step:    11800, Batch Loss:     1.539628, Batch Acc: 0.460233, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 08:42:07,314 - INFO - joeynmt.training - Epoch   3: total training loss 5989.20, num seqs 15756, num tokens 672796
2024-02-21 08:42:07,314 - INFO - joeynmt.training - EPOCH 4
2024-02-21 08:42:46,973 - INFO - joeynmt.training - Epoch   4, Step:    11900, Batch Loss:     1.353387, Batch Acc: 0.468626, Tokens per Sec:      364, Lr: 0.000200
2024-02-21 08:43:36,018 - INFO - joeynmt.training - Epoch   4, Step:    12000, Batch Loss:     1.504811, Batch Acc: 0.470851, Tokens per Sec:      338, Lr: 0.000200
2024-02-21 08:43:36,019 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.16it/s]
2024-02-21 08:44:25,091 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  41.99, loss:   1.50, ppl:   4.49, acc:   0.46, generation: 48.3419[sec], evaluation: 0.7071[sec]
2024-02-21 08:44:25,092 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 08:44:26,192 - INFO - joeynmt.helpers - delete experiment/8000.ckpt
2024-02-21 08:44:26,253 - INFO - joeynmt.training - Example #0
2024-02-21 08:44:26,254 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 08:44:26,255 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 08:44:26,255 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x436S35d10495x456S14c50501x489S14c58469x489S2fb04492x560S26606517x514S26612460x517
2024-02-21 08:44:26,255 - INFO - joeynmt.training - Example #1
2024-02-21 08:44:26,256 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 08:44:26,256 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 08:44:26,256 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S1000a477x502S10002501x489S10002501x489S20500495x477S2fb04492x560S2a208501x509S2a210477x509
2024-02-21 08:44:26,256 - INFO - joeynmt.training - Example #2
2024-02-21 08:44:26,257 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 08:44:26,257 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 08:44:26,257 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00437x456S2ff00517x456S35d10451x477S14c00456x496S14c08437x494S22620456x492S22620456x491S22620456x491S22620469x496S22620469x496S22620469x496S22620510x496S22620510x496S22620510x496
2024-02-21 08:44:26,257 - INFO - joeynmt.training - Example #3
2024-02-21 08:44:26,257 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 08:44:26,258 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 08:44:26,258 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006469x470S35d10484x492S10000502x482S20500496x482S20500496x477S20500496x477S20500496x496S20500496x496
2024-02-21 08:45:13,910 - INFO - joeynmt.training - Epoch   4, Step:    12100, Batch Loss:     1.456470, Batch Acc: 0.476518, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 08:46:01,779 - INFO - joeynmt.training - Epoch   4, Step:    12200, Batch Loss:     1.515905, Batch Acc: 0.468517, Tokens per Sec:      373, Lr: 0.000200
2024-02-21 08:46:50,076 - INFO - joeynmt.training - Epoch   4, Step:    12300, Batch Loss:     1.450974, Batch Acc: 0.468317, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 08:47:38,717 - INFO - joeynmt.training - Epoch   4, Step:    12400, Batch Loss:     1.504459, Batch Acc: 0.471189, Tokens per Sec:      344, Lr: 0.000200
2024-02-21 08:48:26,602 - INFO - joeynmt.training - Epoch   4, Step:    12500, Batch Loss:     1.439843, Batch Acc: 0.479674, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 08:49:14,642 - INFO - joeynmt.training - Epoch   4, Step:    12600, Batch Loss:     1.360198, Batch Acc: 0.469839, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 08:50:02,542 - INFO - joeynmt.training - Epoch   4, Step:    12700, Batch Loss:     1.404558, Batch Acc: 0.473765, Tokens per Sec:      355, Lr: 0.000200
2024-02-21 08:50:50,758 - INFO - joeynmt.training - Epoch   4, Step:    12800, Batch Loss:     1.385513, Batch Acc: 0.469416, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 08:51:38,323 - INFO - joeynmt.training - Epoch   4, Step:    12900, Batch Loss:     1.785895, Batch Acc: 0.468022, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 08:52:26,203 - INFO - joeynmt.training - Epoch   4, Step:    13000, Batch Loss:     1.475380, Batch Acc: 0.476322, Tokens per Sec:      348, Lr: 0.000200
2024-02-21 08:52:26,204 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.08it/s]
2024-02-21 08:53:15,714 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  41.88, loss:   1.49, ppl:   4.42, acc:   0.46, generation: 48.8453[sec], evaluation: 0.6422[sec]
2024-02-21 08:53:16,297 - INFO - joeynmt.helpers - delete experiment/10000.ckpt
2024-02-21 08:53:16,340 - INFO - joeynmt.training - Example #0
2024-02-21 08:53:16,340 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 08:53:16,340 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 08:53:16,341 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x441S35d10495x461S1ce50502x487S1ce58472x489S2fd04489x555S27100509x514S27110458x514
2024-02-21 08:53:16,341 - INFO - joeynmt.training - Example #1
2024-02-21 08:53:16,341 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 08:53:16,341 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 08:53:16,341 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00483x441S35d10496x462S10002496x489S1000a472x489S2ea00510x512S2ea4c472x514S2fd04489x552
2024-02-21 08:53:16,341 - INFO - joeynmt.training - Example #2
2024-02-21 08:53:16,342 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 08:53:16,342 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 08:53:16,342 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00446x449S2ff00517x449S35d10460x472S16d10465x492S16d18446x494S2f900440x525S22a02468x523S16d10465x497S16d18446x496S22a02465x522S22a06537x525S22a06537x525S22a02554x525S22a16499x525S2fb04525x548
2024-02-21 08:53:16,342 - INFO - joeynmt.training - Example #3
2024-02-21 08:53:16,343 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 08:53:16,343 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 08:53:16,343 - INFO - joeynmt.training - 	Hypothesis: M500x500S30007472x472S35d14485x490S10001498x489S20500496x472S20500506x472S20500506x472S20500506x472S2df04506x509
2024-02-21 08:54:05,154 - INFO - joeynmt.training - Epoch   4, Step:    13100, Batch Loss:     1.697773, Batch Acc: 0.473459, Tokens per Sec:      349, Lr: 0.000200
2024-02-21 08:54:53,496 - INFO - joeynmt.training - Epoch   4, Step:    13200, Batch Loss:     1.455815, Batch Acc: 0.471570, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 08:55:41,385 - INFO - joeynmt.training - Epoch   4, Step:    13300, Batch Loss:     1.349353, Batch Acc: 0.475664, Tokens per Sec:      376, Lr: 0.000200
2024-02-21 08:56:29,427 - INFO - joeynmt.training - Epoch   4, Step:    13400, Batch Loss:     1.453717, Batch Acc: 0.473214, Tokens per Sec:      371, Lr: 0.000200
2024-02-21 08:57:17,010 - INFO - joeynmt.training - Epoch   4, Step:    13500, Batch Loss:     1.890016, Batch Acc: 0.477890, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 08:58:05,839 - INFO - joeynmt.training - Epoch   4, Step:    13600, Batch Loss:     1.440295, Batch Acc: 0.477210, Tokens per Sec:      342, Lr: 0.000200
2024-02-21 08:58:54,381 - INFO - joeynmt.training - Epoch   4, Step:    13700, Batch Loss:     1.160014, Batch Acc: 0.472074, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 08:59:42,749 - INFO - joeynmt.training - Epoch   4, Step:    13800, Batch Loss:     1.613744, Batch Acc: 0.474439, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 09:00:30,314 - INFO - joeynmt.training - Epoch   4, Step:    13900, Batch Loss:     1.607861, Batch Acc: 0.481625, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 09:01:17,870 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     1.248875, Batch Acc: 0.478339, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 09:01:17,870 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:46<00:00,  7.40it/s]
2024-02-21 09:02:05,264 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  42.48, loss:   1.48, ppl:   4.38, acc:   0.47, generation: 46.7432[sec], evaluation: 0.6283[sec]
2024-02-21 09:02:05,265 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 09:02:05,831 - INFO - joeynmt.helpers - delete experiment/13000.ckpt
2024-02-21 09:02:05,872 - INFO - joeynmt.training - Example #0
2024-02-21 09:02:05,873 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 09:02:05,873 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 09:02:05,873 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x441S35d14495x461S20350501x492S20358483x490S20500495x492S2fb04492x554S26606507x518S26612466x518
2024-02-21 09:02:05,873 - INFO - joeynmt.training - Example #1
2024-02-21 09:02:05,875 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 09:02:05,875 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 09:02:05,875 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x444S35d14495x464S1000a477x492S10002501x492S20500495x492S20500495x492S22b06507x517S22b12469x517S2fb04492x551
2024-02-21 09:02:05,875 - INFO - joeynmt.training - Example #2
2024-02-21 09:02:05,875 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 09:02:05,875 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 09:02:05,875 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00439x451S2ff00506x451S35d14451x471S18510451x491S18518430x497S20500449x504S20500447x504S22b06430x517S22b12430x520S2fb04451x549
2024-02-21 09:02:05,875 - INFO - joeynmt.training - Example #3
2024-02-21 09:02:05,876 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 09:02:05,876 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 09:02:05,876 - INFO - joeynmt.training - 	Hypothesis: M500x500S30007471x469S30007471x488S35d14488x490S20500507x471S20500471x471S26a04505x504S10000507x475
2024-02-21 09:02:54,302 - INFO - joeynmt.training - Epoch   4, Step:    14100, Batch Loss:     1.150083, Batch Acc: 0.483465, Tokens per Sec:      348, Lr: 0.000200
2024-02-21 09:03:41,422 - INFO - joeynmt.training - Epoch   4, Step:    14200, Batch Loss:     1.401390, Batch Acc: 0.477200, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 09:04:29,951 - INFO - joeynmt.training - Epoch   4, Step:    14300, Batch Loss:     1.172133, Batch Acc: 0.474287, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 09:05:18,026 - INFO - joeynmt.training - Epoch   4, Step:    14400, Batch Loss:     1.189401, Batch Acc: 0.488499, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 09:06:08,679 - INFO - joeynmt.training - Epoch   4, Step:    14500, Batch Loss:     1.437238, Batch Acc: 0.481540, Tokens per Sec:      338, Lr: 0.000200
2024-02-21 09:06:57,527 - INFO - joeynmt.training - Epoch   4, Step:    14600, Batch Loss:     1.402852, Batch Acc: 0.479795, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 09:07:44,713 - INFO - joeynmt.training - Epoch   4, Step:    14700, Batch Loss:     1.480492, Batch Acc: 0.484233, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 09:08:33,454 - INFO - joeynmt.training - Epoch   4, Step:    14800, Batch Loss:     1.434729, Batch Acc: 0.477822, Tokens per Sec:      368, Lr: 0.000200
2024-02-21 09:09:23,363 - INFO - joeynmt.training - Epoch   4, Step:    14900, Batch Loss:     1.628460, Batch Acc: 0.487829, Tokens per Sec:      338, Lr: 0.000200
2024-02-21 09:10:11,860 - INFO - joeynmt.training - Epoch   4, Step:    15000, Batch Loss:     1.501607, Batch Acc: 0.482826, Tokens per Sec:      349, Lr: 0.000200
2024-02-21 09:10:11,860 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:51<00:00,  6.78it/s]
2024-02-21 09:11:03,589 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  43.43, loss:   1.46, ppl:   4.29, acc:   0.47, generation: 51.0263[sec], evaluation: 0.6797[sec]
2024-02-21 09:11:03,589 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 09:11:08,631 - INFO - joeynmt.helpers - delete experiment/12000.ckpt
2024-02-21 09:11:08,674 - INFO - joeynmt.training - Example #0
2024-02-21 09:11:08,674 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 09:11:08,674 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 09:11:08,675 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S20350501x475S20358476x483S26606501x483S26612472x483S2fb04492x561S22200501x483S22200483x483S22200483x483S22200501x483S22200476x483S22200483x483S22200483x483S22200511x483S22200511x476S22200467x476S22200511x476
2024-02-21 09:11:08,675 - INFO - joeynmt.training - Example #1
2024-02-21 09:11:08,676 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 09:11:08,676 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 09:11:08,676 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S1000a476x475S10002501x475S2ea00501x501S2ea4c476x508S2fd04489x560
2024-02-21 09:11:08,676 - INFO - joeynmt.training - Example #2
2024-02-21 09:11:08,676 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 09:11:08,676 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 09:11:08,676 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00448x434S2ff00510x434S35d14461x454S1ce10463x472S2e500460x501S2e500463x501S2e518432x501S2fd04456x560S1ce10531x477S1ce10501x477
2024-02-21 09:11:08,676 - INFO - joeynmt.training - Example #3
2024-02-21 09:11:08,677 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 09:11:08,677 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 09:11:08,677 - INFO - joeynmt.training - 	Hypothesis: M500x500S30004482x470S35d14495x490S10000501x482S20500495x472S20500495x472S20500495x472S20500495x485
2024-02-21 09:11:57,597 - INFO - joeynmt.training - Epoch   4, Step:    15100, Batch Loss:     1.399098, Batch Acc: 0.481329, Tokens per Sec:      323, Lr: 0.000200
2024-02-21 09:12:46,610 - INFO - joeynmt.training - Epoch   4, Step:    15200, Batch Loss:     1.801069, Batch Acc: 0.480102, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 09:13:36,306 - INFO - joeynmt.training - Epoch   4, Step:    15300, Batch Loss:     1.388521, Batch Acc: 0.484319, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 09:14:23,587 - INFO - joeynmt.training - Epoch   4, Step:    15400, Batch Loss:     1.546651, Batch Acc: 0.489126, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 09:15:11,542 - INFO - joeynmt.training - Epoch   4, Step:    15500, Batch Loss:     1.584193, Batch Acc: 0.487015, Tokens per Sec:      344, Lr: 0.000200
2024-02-21 09:15:59,452 - INFO - joeynmt.training - Epoch   4, Step:    15600, Batch Loss:     1.232851, Batch Acc: 0.484226, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 09:16:48,563 - INFO - joeynmt.training - Epoch   4, Step:    15700, Batch Loss:     1.459081, Batch Acc: 0.485584, Tokens per Sec:      336, Lr: 0.000200
2024-02-21 09:17:15,354 - INFO - joeynmt.training - Epoch   4: total training loss 5636.42, num seqs 15756, num tokens 672796
2024-02-21 09:17:15,354 - INFO - joeynmt.training - EPOCH 5
2024-02-21 09:17:35,899 - INFO - joeynmt.training - Epoch   5, Step:    15800, Batch Loss:     1.690780, Batch Acc: 0.495621, Tokens per Sec:      378, Lr: 0.000200
2024-02-21 09:18:24,134 - INFO - joeynmt.training - Epoch   5, Step:    15900, Batch Loss:     1.616606, Batch Acc: 0.495738, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 09:19:12,163 - INFO - joeynmt.training - Epoch   5, Step:    16000, Batch Loss:     1.045912, Batch Acc: 0.490581, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 09:19:12,163 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:49<00:00,  6.92it/s]
2024-02-21 09:20:02,799 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  43.73, loss:   1.45, ppl:   4.27, acc:   0.47, generation: 49.9677[sec], evaluation: 0.6451[sec]
2024-02-21 09:20:02,800 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 09:20:03,349 - INFO - joeynmt.helpers - delete experiment/14000.ckpt
2024-02-21 09:20:03,389 - INFO - joeynmt.training - Example #0
2024-02-21 09:20:03,390 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 09:20:03,390 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 09:20:03,390 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x561S26606503x474S26612469x474S20500495x473S20500495x473
2024-02-21 09:20:03,390 - INFO - joeynmt.training - Example #1
2024-02-21 09:20:03,391 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 09:20:03,391 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 09:20:03,391 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S20500495x477S2fb04492x560S22b06501x506S22b12475x506S22b16467x506S22b02508x506S22b16475x506
2024-02-21 09:20:03,391 - INFO - joeynmt.training - Example #2
2024-02-21 09:20:03,392 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 09:20:03,392 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 09:20:03,392 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00446x451S2ff00508x451S35d14459x471S1ce10460x491S2e500460x517S1ce10532x492S1ce18499x494S2f900502x535
2024-02-21 09:20:03,392 - INFO - joeynmt.training - Example #3
2024-02-21 09:20:03,392 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 09:20:03,392 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 09:20:03,393 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x461S35d14495x481S10000502x498S2e500495x517
2024-02-21 09:20:51,546 - INFO - joeynmt.training - Epoch   5, Step:    16100, Batch Loss:     1.368850, Batch Acc: 0.497659, Tokens per Sec:      351, Lr: 0.000200
2024-02-21 09:21:39,650 - INFO - joeynmt.training - Epoch   5, Step:    16200, Batch Loss:     1.119936, Batch Acc: 0.504528, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 09:22:27,650 - INFO - joeynmt.training - Epoch   5, Step:    16300, Batch Loss:     1.233114, Batch Acc: 0.493694, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 09:23:15,559 - INFO - joeynmt.training - Epoch   5, Step:    16400, Batch Loss:     1.536289, Batch Acc: 0.497137, Tokens per Sec:      339, Lr: 0.000200
2024-02-21 09:24:02,683 - INFO - joeynmt.training - Epoch   5, Step:    16500, Batch Loss:     1.389938, Batch Acc: 0.500865, Tokens per Sec:      368, Lr: 0.000200
2024-02-21 09:24:52,052 - INFO - joeynmt.training - Epoch   5, Step:    16600, Batch Loss:     1.321492, Batch Acc: 0.491608, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 09:25:40,077 - INFO - joeynmt.training - Epoch   5, Step:    16700, Batch Loss:     1.503762, Batch Acc: 0.498330, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 09:26:27,768 - INFO - joeynmt.training - Epoch   5, Step:    16800, Batch Loss:     1.455217, Batch Acc: 0.496243, Tokens per Sec:      349, Lr: 0.000200
2024-02-21 09:27:14,382 - INFO - joeynmt.training - Epoch   5, Step:    16900, Batch Loss:     1.416094, Batch Acc: 0.496358, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 09:28:03,528 - INFO - joeynmt.training - Epoch   5, Step:    17000, Batch Loss:     1.254943, Batch Acc: 0.494887, Tokens per Sec:      334, Lr: 0.000200
2024-02-21 09:28:03,528 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:44<00:00,  7.71it/s]
2024-02-21 09:28:49,020 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  43.24, loss:   1.45, ppl:   4.25, acc:   0.48, generation: 44.8854[sec], evaluation: 0.5849[sec]
2024-02-21 09:28:49,021 - INFO - joeynmt.training - Example #0
2024-02-21 09:28:49,022 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 09:28:49,022 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 09:28:49,022 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x440S35d10495x460S14c50501x488S14c58469x488S2fc04492x552S22520504x479S22520467x479S22520467x480S22520504x476
2024-02-21 09:28:49,022 - INFO - joeynmt.training - Example #1
2024-02-21 09:28:49,023 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 09:28:49,023 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 09:28:49,023 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x440S35d10495x460S10002501x495S1000a467x495S2fb04492x555S20500495x479S2ea00504x514S2ea4c476x513
2024-02-21 09:28:49,023 - INFO - joeynmt.training - Example #2
2024-02-21 09:28:49,023 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 09:28:49,023 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 09:28:49,024 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x440S2ff00507x440S35d10453x460S1ce10458x480S2e500458x509S2e500458x514S2fd04517x555S2e518499x514S1ce10530x477S2e500527x504
2024-02-21 09:28:49,024 - INFO - joeynmt.training - Example #3
2024-02-21 09:28:49,024 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 09:28:49,024 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 09:28:49,024 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00475x459S35d10487x479S10000496x505S2e500505x517
2024-02-21 09:29:36,209 - INFO - joeynmt.training - Epoch   5, Step:    17100, Batch Loss:     1.164745, Batch Acc: 0.496979, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 09:30:24,308 - INFO - joeynmt.training - Epoch   5, Step:    17200, Batch Loss:     1.146598, Batch Acc: 0.493739, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 09:31:12,514 - INFO - joeynmt.training - Epoch   5, Step:    17300, Batch Loss:     1.224939, Batch Acc: 0.495575, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 09:32:01,809 - INFO - joeynmt.training - Epoch   5, Step:    17400, Batch Loss:     1.220047, Batch Acc: 0.502041, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 09:32:50,509 - INFO - joeynmt.training - Epoch   5, Step:    17500, Batch Loss:     1.158994, Batch Acc: 0.501322, Tokens per Sec:      349, Lr: 0.000200
2024-02-21 09:33:38,092 - INFO - joeynmt.training - Epoch   5, Step:    17600, Batch Loss:     1.214019, Batch Acc: 0.505971, Tokens per Sec:      364, Lr: 0.000200
2024-02-21 09:34:26,750 - INFO - joeynmt.training - Epoch   5, Step:    17700, Batch Loss:     1.971552, Batch Acc: 0.496064, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 09:35:15,413 - INFO - joeynmt.training - Epoch   5, Step:    17800, Batch Loss:     1.139590, Batch Acc: 0.495789, Tokens per Sec:      351, Lr: 0.000200
2024-02-21 09:36:04,773 - INFO - joeynmt.training - Epoch   5, Step:    17900, Batch Loss:     1.332697, Batch Acc: 0.500801, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 09:36:51,858 - INFO - joeynmt.training - Epoch   5, Step:    18000, Batch Loss:     1.157510, Batch Acc: 0.503511, Tokens per Sec:      372, Lr: 0.000200
2024-02-21 09:36:51,859 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.18it/s]
2024-02-21 09:37:40,741 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  43.61, loss:   1.44, ppl:   4.21, acc:   0.48, generation: 48.1740[sec], evaluation: 0.6839[sec]
2024-02-21 09:37:45,799 - INFO - joeynmt.helpers - delete experiment/15000.ckpt
2024-02-21 09:37:45,841 - INFO - joeynmt.training - Example #0
2024-02-21 09:37:45,842 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 09:37:45,842 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 09:37:45,842 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S2fb04492x561S20350501x482S20358483x482S26606507x482S26612468x482
2024-02-21 09:37:45,842 - INFO - joeynmt.training - Example #1
2024-02-21 09:37:45,843 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 09:37:45,843 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 09:37:45,843 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S1000a473x492S10002501x488S2ea00507x493S2ea4c474x507S2fd04489x560
2024-02-21 09:37:45,843 - INFO - joeynmt.training - Example #2
2024-02-21 09:37:45,843 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 09:37:45,843 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 09:37:45,843 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00436x457S2ff00509x457S35d14448x477S1ce10531x478S2e500531x502S2e518500x514S1ce10456x495S1ce10531x495S2e500456x514
2024-02-21 09:37:45,844 - INFO - joeynmt.training - Example #3
2024-02-21 09:37:45,844 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 09:37:45,844 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 09:37:45,844 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006471x470S35d10482x488S10010502x482S20500502x482S26a04502x507
2024-02-21 09:38:33,731 - INFO - joeynmt.training - Epoch   5, Step:    18100, Batch Loss:     1.447844, Batch Acc: 0.497755, Tokens per Sec:      328, Lr: 0.000200
2024-02-21 09:39:23,171 - INFO - joeynmt.training - Epoch   5, Step:    18200, Batch Loss:     1.275652, Batch Acc: 0.503914, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 09:40:12,820 - INFO - joeynmt.training - Epoch   5, Step:    18300, Batch Loss:     1.572414, Batch Acc: 0.501776, Tokens per Sec:      340, Lr: 0.000200
2024-02-21 09:41:01,560 - INFO - joeynmt.training - Epoch   5, Step:    18400, Batch Loss:     1.315560, Batch Acc: 0.505493, Tokens per Sec:      353, Lr: 0.000200
2024-02-21 09:41:50,031 - INFO - joeynmt.training - Epoch   5, Step:    18500, Batch Loss:     1.486711, Batch Acc: 0.499147, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 09:42:37,494 - INFO - joeynmt.training - Epoch   5, Step:    18600, Batch Loss:     1.573218, Batch Acc: 0.506283, Tokens per Sec:      366, Lr: 0.000200
2024-02-21 09:43:27,042 - INFO - joeynmt.training - Epoch   5, Step:    18700, Batch Loss:     1.216863, Batch Acc: 0.500318, Tokens per Sec:      349, Lr: 0.000200
2024-02-21 09:44:15,651 - INFO - joeynmt.training - Epoch   5, Step:    18800, Batch Loss:     1.171581, Batch Acc: 0.504488, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 09:45:04,714 - INFO - joeynmt.training - Epoch   5, Step:    18900, Batch Loss:     1.429384, Batch Acc: 0.498831, Tokens per Sec:      349, Lr: 0.000200
2024-02-21 09:45:52,399 - INFO - joeynmt.training - Epoch   5, Step:    19000, Batch Loss:     1.483009, Batch Acc: 0.505298, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 09:45:52,400 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:44<00:00,  7.70it/s]
2024-02-21 09:46:37,983 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  43.66, loss:   1.43, ppl:   4.16, acc:   0.48, generation: 44.9485[sec], evaluation: 0.6123[sec]
2024-02-21 09:46:38,530 - INFO - joeynmt.helpers - delete experiment/18000.ckpt
2024-02-21 09:46:38,571 - INFO - joeynmt.helpers - delete /content/signwriting-transcription/experiment/18000.ckpt
2024-02-21 09:46:38,571 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/signwriting-transcription/experiment/18000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/signwriting-transcription/experiment/18000.ckpt')
2024-02-21 09:46:38,572 - INFO - joeynmt.training - Example #0
2024-02-21 09:46:38,572 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 09:46:38,573 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 09:46:38,573 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x441S35d10495x461S14c50501x489S14c58475x489S2fb04492x554S20500495x488S22b06506x513S22b12473x513
2024-02-21 09:46:38,573 - INFO - joeynmt.training - Example #1
2024-02-21 09:46:38,573 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 09:46:38,573 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 09:46:38,573 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d10495x455S1000a476x491S10002501x488S2ea00507x493S2ea4c476x508S2fd04489x560
2024-02-21 09:46:38,574 - INFO - joeynmt.training - Example #2
2024-02-21 09:46:38,574 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 09:46:38,574 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 09:46:38,574 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00437x450S2ff00510x450S35d10450x470S1ce10461x473S2e500460x514S15a18506x498S15a10529x501S20500521x503S2f900506x536S22a04546x521
2024-02-21 09:46:38,574 - INFO - joeynmt.training - Example #3
2024-02-21 09:46:38,575 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 09:46:38,575 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 09:46:38,575 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006475x475S35d10487x491S10010500x500S21100506x472S26a04507x498
2024-02-21 09:47:28,342 - INFO - joeynmt.training - Epoch   5, Step:    19100, Batch Loss:     1.309637, Batch Acc: 0.504384, Tokens per Sec:      337, Lr: 0.000200
2024-02-21 09:48:17,009 - INFO - joeynmt.training - Epoch   5, Step:    19200, Batch Loss:     1.438228, Batch Acc: 0.509407, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 09:49:04,383 - INFO - joeynmt.training - Epoch   5, Step:    19300, Batch Loss:     1.188794, Batch Acc: 0.499882, Tokens per Sec:      358, Lr: 0.000200
2024-02-21 09:49:53,280 - INFO - joeynmt.training - Epoch   5, Step:    19400, Batch Loss:     1.591998, Batch Acc: 0.504643, Tokens per Sec:      344, Lr: 0.000200
2024-02-21 09:50:42,489 - INFO - joeynmt.training - Epoch   5, Step:    19500, Batch Loss:     1.355392, Batch Acc: 0.502912, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 09:51:32,618 - INFO - joeynmt.training - Epoch   5, Step:    19600, Batch Loss:     1.346043, Batch Acc: 0.504369, Tokens per Sec:      331, Lr: 0.000200
2024-02-21 09:52:17,701 - INFO - joeynmt.training - Epoch   5: total training loss 5353.09, num seqs 15756, num tokens 672796
2024-02-21 09:52:17,702 - INFO - joeynmt.training - EPOCH 6
2024-02-21 09:52:20,899 - INFO - joeynmt.training - Epoch   6, Step:    19700, Batch Loss:     1.347824, Batch Acc: 0.509677, Tokens per Sec:      291, Lr: 0.000200
2024-02-21 09:53:08,126 - INFO - joeynmt.training - Epoch   6, Step:    19800, Batch Loss:     0.978153, Batch Acc: 0.517473, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 09:53:56,033 - INFO - joeynmt.training - Epoch   6, Step:    19900, Batch Loss:     1.246456, Batch Acc: 0.518813, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 09:54:44,560 - INFO - joeynmt.training - Epoch   6, Step:    20000, Batch Loss:     1.706548, Batch Acc: 0.512855, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 09:54:44,560 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:50<00:00,  6.90it/s]
2024-02-21 09:55:35,398 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  45.10, loss:   1.43, ppl:   4.16, acc:   0.48, generation: 50.1483[sec], evaluation: 0.6625[sec]
2024-02-21 09:55:35,399 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 09:55:40,439 - INFO - joeynmt.helpers - delete experiment/19000.ckpt
2024-02-21 09:55:40,482 - INFO - joeynmt.training - Example #0
2024-02-21 09:55:40,482 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 09:55:40,482 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 09:55:40,482 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x441S35d10495x461S14c50501x483S14c58474x483S20500495x509S26606509x513S26612466x513S2fb04492x553
2024-02-21 09:55:40,483 - INFO - joeynmt.training - Example #1
2024-02-21 09:55:40,484 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 09:55:40,484 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 09:55:40,484 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S20500495x477S2fb04492x560S22f02501x509S22f16478x513
2024-02-21 09:55:40,484 - INFO - joeynmt.training - Example #2
2024-02-21 09:55:40,484 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 09:55:40,484 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 09:55:40,484 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00441x441S2ff00514x441S35d10454x461S1ce10468x474S2e500454x509S1ce10531x478S1ce18500x478S2fd04516x553S2e500546x509S2e518497x509
2024-02-21 09:55:40,484 - INFO - joeynmt.training - Example #3
2024-02-21 09:55:40,485 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 09:55:40,485 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 09:55:40,485 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006482x471S30006482x471S35d10495x489S20500495x472S26a04493x515S10000494x469
2024-02-21 09:56:28,719 - INFO - joeynmt.training - Epoch   6, Step:    20100, Batch Loss:     1.246759, Batch Acc: 0.515268, Tokens per Sec:      322, Lr: 0.000200
2024-02-21 09:57:17,129 - INFO - joeynmt.training - Epoch   6, Step:    20200, Batch Loss:     1.345552, Batch Acc: 0.513965, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 09:58:04,219 - INFO - joeynmt.training - Epoch   6, Step:    20300, Batch Loss:     1.458506, Batch Acc: 0.521827, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 09:58:52,099 - INFO - joeynmt.training - Epoch   6, Step:    20400, Batch Loss:     1.243712, Batch Acc: 0.519524, Tokens per Sec:      358, Lr: 0.000200
2024-02-21 09:59:41,155 - INFO - joeynmt.training - Epoch   6, Step:    20500, Batch Loss:     1.414923, Batch Acc: 0.525087, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 10:00:29,448 - INFO - joeynmt.training - Epoch   6, Step:    20600, Batch Loss:     0.977799, Batch Acc: 0.514595, Tokens per Sec:      364, Lr: 0.000200
2024-02-21 10:01:16,702 - INFO - joeynmt.training - Epoch   6, Step:    20700, Batch Loss:     1.288462, Batch Acc: 0.524594, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 10:02:04,814 - INFO - joeynmt.training - Epoch   6, Step:    20800, Batch Loss:     1.410462, Batch Acc: 0.523599, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 10:02:52,774 - INFO - joeynmt.training - Epoch   6, Step:    20900, Batch Loss:     1.079342, Batch Acc: 0.518220, Tokens per Sec:      351, Lr: 0.000200
2024-02-21 10:03:41,624 - INFO - joeynmt.training - Epoch   6, Step:    21000, Batch Loss:     1.003696, Batch Acc: 0.522865, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 10:03:41,625 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:44<00:00,  7.72it/s]
2024-02-21 10:04:27,078 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  43.53, loss:   1.43, ppl:   4.17, acc:   0.49, generation: 44.8060[sec], evaluation: 0.6234[sec]
2024-02-21 10:04:27,079 - INFO - joeynmt.training - Example #0
2024-02-21 10:04:27,080 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 10:04:27,080 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 10:04:27,080 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x441S35d14495x461S14c50503x489S14c58475x489S2fb04492x552S26607505x480S26611469x480
2024-02-21 10:04:27,080 - INFO - joeynmt.training - Example #1
2024-02-21 10:04:27,080 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 10:04:27,080 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 10:04:27,081 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S10002501x484S1000a475x484S2ea00508x508S2ea4c476x508S2fd04489x560
2024-02-21 10:04:27,081 - INFO - joeynmt.training - Example #2
2024-02-21 10:04:27,081 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 10:04:27,081 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 10:04:27,081 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x443S2ff00514x443S35d14454x463S18507536x484S1851f495x484S21100454x488S2fb04522x552S18517536x481S1851f506x481S21100532x481S26b04529x510
2024-02-21 10:04:27,081 - INFO - joeynmt.training - Example #3
2024-02-21 10:04:27,082 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 10:04:27,082 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 10:04:27,082 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00474x463S35d14487x484S10001498x488S2ea06506x522
2024-02-21 10:05:15,265 - INFO - joeynmt.training - Epoch   6, Step:    21100, Batch Loss:     1.002105, Batch Acc: 0.522007, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 10:06:03,512 - INFO - joeynmt.training - Epoch   6, Step:    21200, Batch Loss:     1.207245, Batch Acc: 0.519869, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 10:06:52,420 - INFO - joeynmt.training - Epoch   6, Step:    21300, Batch Loss:     1.259426, Batch Acc: 0.514805, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 10:07:39,467 - INFO - joeynmt.training - Epoch   6, Step:    21400, Batch Loss:     1.320954, Batch Acc: 0.517282, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 10:08:27,139 - INFO - joeynmt.training - Epoch   6, Step:    21500, Batch Loss:     1.169051, Batch Acc: 0.524319, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 10:09:15,271 - INFO - joeynmt.training - Epoch   6, Step:    21600, Batch Loss:     1.438565, Batch Acc: 0.523113, Tokens per Sec:      351, Lr: 0.000200
2024-02-21 10:10:02,747 - INFO - joeynmt.training - Epoch   6, Step:    21700, Batch Loss:     0.964558, Batch Acc: 0.521379, Tokens per Sec:      364, Lr: 0.000200
2024-02-21 10:10:51,867 - INFO - joeynmt.training - Epoch   6, Step:    21800, Batch Loss:     1.371806, Batch Acc: 0.525245, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 10:11:39,643 - INFO - joeynmt.training - Epoch   6, Step:    21900, Batch Loss:     1.175925, Batch Acc: 0.522154, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 10:12:27,561 - INFO - joeynmt.training - Epoch   6, Step:    22000, Batch Loss:     1.237700, Batch Acc: 0.516571, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 10:12:27,561 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:44<00:00,  7.86it/s]
2024-02-21 10:13:12,208 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  43.92, loss:   1.42, ppl:   4.14, acc:   0.49, generation: 44.0226[sec], evaluation: 0.6022[sec]
2024-02-21 10:13:12,794 - INFO - joeynmt.helpers - delete experiment/16000.ckpt
2024-02-21 10:13:12,839 - INFO - joeynmt.training - Example #0
2024-02-21 10:13:12,840 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 10:13:12,840 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 10:13:12,841 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S26606501x504S26612468x505S2fb04493x561S20500495x472S2fb04493x561
2024-02-21 10:13:12,841 - INFO - joeynmt.training - Example #1
2024-02-21 10:13:12,841 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 10:13:12,841 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 10:13:12,842 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S10002501x483S1000a475x482S2ea00508x495S2ea4c476x495S2fd04489x560
2024-02-21 10:13:12,842 - INFO - joeynmt.training - Example #2
2024-02-21 10:13:12,842 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 10:13:12,842 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 10:13:12,842 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x440S2ff00514x440S35d14453x460S14c20463x463S14428429x483S27202463x511S27212429x511S2fb04449x554S15310543x481S15318514x481
2024-02-21 10:13:12,842 - INFO - joeynmt.training - Example #3
2024-02-21 10:13:12,843 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 10:13:12,843 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 10:13:12,843 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006482x470S35d10495x489S10001501x470S21100506x470S20500501x470S20500501x470S20500507x470
2024-02-21 10:14:01,097 - INFO - joeynmt.training - Epoch   6, Step:    22100, Batch Loss:     1.210415, Batch Acc: 0.528368, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 10:14:50,811 - INFO - joeynmt.training - Epoch   6, Step:    22200, Batch Loss:     1.212058, Batch Acc: 0.516435, Tokens per Sec:      340, Lr: 0.000200
2024-02-21 10:15:38,693 - INFO - joeynmt.training - Epoch   6, Step:    22300, Batch Loss:     1.334897, Batch Acc: 0.524554, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 10:16:26,020 - INFO - joeynmt.training - Epoch   6, Step:    22400, Batch Loss:     1.171391, Batch Acc: 0.521468, Tokens per Sec:      366, Lr: 0.000200
2024-02-21 10:17:13,995 - INFO - joeynmt.training - Epoch   6, Step:    22500, Batch Loss:     1.201674, Batch Acc: 0.526148, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 10:18:02,557 - INFO - joeynmt.training - Epoch   6, Step:    22600, Batch Loss:     1.393365, Batch Acc: 0.524126, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 10:18:52,293 - INFO - joeynmt.training - Epoch   6, Step:    22700, Batch Loss:     1.662908, Batch Acc: 0.525039, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 10:19:39,277 - INFO - joeynmt.training - Epoch   6, Step:    22800, Batch Loss:     1.041313, Batch Acc: 0.524906, Tokens per Sec:      368, Lr: 0.000200
2024-02-21 10:20:27,137 - INFO - joeynmt.training - Epoch   6, Step:    22900, Batch Loss:     1.485059, Batch Acc: 0.519092, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 10:21:15,487 - INFO - joeynmt.training - Epoch   6, Step:    23000, Batch Loss:     1.262111, Batch Acc: 0.529578, Tokens per Sec:      358, Lr: 0.000200
2024-02-21 10:21:15,488 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:50<00:00,  6.81it/s]
2024-02-21 10:22:06,970 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  43.61, loss:   1.41, ppl:   4.10, acc:   0.49, generation: 50.7970[sec], evaluation: 0.6604[sec]
2024-02-21 10:22:06,971 - INFO - joeynmt.training - Example #0
2024-02-21 10:22:06,972 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 10:22:06,972 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 10:22:06,972 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S26606503x502S26612467x502S2fb04492x561S20350502x489S20350489x489S22200502x489S22200502x489S22200479x489S22200502x489S22200502x489
2024-02-21 10:22:06,972 - INFO - joeynmt.training - Example #1
2024-02-21 10:22:06,973 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 10:22:06,973 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 10:22:06,973 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00483x434S35d14496x454S1000a473x488S10002496x488S1000a473x488S2ea00508x508S2ea4c476x508S2fd04489x560
2024-02-21 10:22:06,973 - INFO - joeynmt.training - Example #2
2024-02-21 10:22:06,974 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 10:22:06,974 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 10:22:06,974 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x455S2ff00513x455S35d14453x475S1ce10465x473S2e500453x502S2e518432x502S15a10537x502S15a18506x502S20500525x502S2f900506x537S2df00537x520
2024-02-21 10:22:06,974 - INFO - joeynmt.training - Example #3
2024-02-21 10:22:06,974 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 10:22:06,974 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 10:22:06,974 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00446x467S30006507x467S35d10459x487S10010470x488S20500459x479S26a04470x500S10010526x488S26a04531x507
2024-02-21 10:22:56,070 - INFO - joeynmt.training - Epoch   6, Step:    23100, Batch Loss:     1.048333, Batch Acc: 0.518430, Tokens per Sec:      340, Lr: 0.000200
2024-02-21 10:23:42,838 - INFO - joeynmt.training - Epoch   6, Step:    23200, Batch Loss:     0.850078, Batch Acc: 0.508187, Tokens per Sec:      366, Lr: 0.000200
2024-02-21 10:24:31,273 - INFO - joeynmt.training - Epoch   6, Step:    23300, Batch Loss:     1.096739, Batch Acc: 0.515980, Tokens per Sec:      348, Lr: 0.000200
2024-02-21 10:25:19,605 - INFO - joeynmt.training - Epoch   6, Step:    23400, Batch Loss:     1.222119, Batch Acc: 0.526127, Tokens per Sec:      374, Lr: 0.000200
2024-02-21 10:26:07,765 - INFO - joeynmt.training - Epoch   6, Step:    23500, Batch Loss:     1.047822, Batch Acc: 0.521853, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 10:26:56,074 - INFO - joeynmt.training - Epoch   6, Step:    23600, Batch Loss:     1.408702, Batch Acc: 0.515746, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 10:27:12,970 - INFO - joeynmt.training - Epoch   6: total training loss 5105.44, num seqs 15756, num tokens 672796
2024-02-21 10:27:12,970 - INFO - joeynmt.training - EPOCH 7
2024-02-21 10:27:43,779 - INFO - joeynmt.training - Epoch   7, Step:    23700, Batch Loss:     1.493881, Batch Acc: 0.542489, Tokens per Sec:      355, Lr: 0.000200
2024-02-21 10:28:31,647 - INFO - joeynmt.training - Epoch   7, Step:    23800, Batch Loss:     1.085770, Batch Acc: 0.538107, Tokens per Sec:      358, Lr: 0.000200
2024-02-21 10:29:19,729 - INFO - joeynmt.training - Epoch   7, Step:    23900, Batch Loss:     1.126587, Batch Acc: 0.539456, Tokens per Sec:      367, Lr: 0.000200
2024-02-21 10:30:06,495 - INFO - joeynmt.training - Epoch   7, Step:    24000, Batch Loss:     1.133168, Batch Acc: 0.537325, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 10:30:06,495 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.12it/s]
2024-02-21 10:30:55,753 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  44.22, loss:   1.41, ppl:   4.11, acc:   0.49, generation: 48.5940[sec], evaluation: 0.6403[sec]
2024-02-21 10:30:59,755 - INFO - joeynmt.helpers - delete experiment/22000.ckpt
2024-02-21 10:30:59,795 - INFO - joeynmt.helpers - delete /content/signwriting-transcription/experiment/22000.ckpt
2024-02-21 10:30:59,796 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/signwriting-transcription/experiment/22000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/signwriting-transcription/experiment/22000.ckpt')
2024-02-21 10:30:59,800 - INFO - joeynmt.training - Example #0
2024-02-21 10:30:59,808 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 10:30:59,810 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 10:30:59,812 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S26606503x514S26612467x494S2fb04492x561S20350501x483S20358483x483
2024-02-21 10:30:59,814 - INFO - joeynmt.training - Example #1
2024-02-21 10:30:59,821 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 10:30:59,823 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 10:30:59,825 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S20500495x473S2fb04493x561S22f02504x497S22f16476x497S10002476x486S1000a473x486
2024-02-21 10:30:59,827 - INFO - joeynmt.training - Example #2
2024-02-21 10:30:59,833 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 10:30:59,835 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 10:30:59,839 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00448x449S2ff00509x449S35d14461x469S1ce10468x449S1ce18448x449S20500461x449S2fc04461x546S1cf10537x486S2e300537x516S2e510476x517
2024-02-21 10:30:59,841 - INFO - joeynmt.training - Example #3
2024-02-21 10:30:59,847 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 10:30:59,849 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 10:30:59,852 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006469x482S35d10482x497S10011498x488S20500482x477S26a04505x499
2024-02-21 10:31:47,823 - INFO - joeynmt.training - Epoch   7, Step:    24100, Batch Loss:     1.086503, Batch Acc: 0.532965, Tokens per Sec:      327, Lr: 0.000200
2024-02-21 10:32:35,490 - INFO - joeynmt.training - Epoch   7, Step:    24200, Batch Loss:     0.959027, Batch Acc: 0.532971, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 10:33:23,037 - INFO - joeynmt.training - Epoch   7, Step:    24300, Batch Loss:     0.918019, Batch Acc: 0.540056, Tokens per Sec:      370, Lr: 0.000200
2024-02-21 10:34:11,228 - INFO - joeynmt.training - Epoch   7, Step:    24400, Batch Loss:     1.066513, Batch Acc: 0.539356, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 10:35:00,172 - INFO - joeynmt.training - Epoch   7, Step:    24500, Batch Loss:     1.384217, Batch Acc: 0.539761, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 10:35:47,989 - INFO - joeynmt.training - Epoch   7, Step:    24600, Batch Loss:     1.221118, Batch Acc: 0.539504, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 10:36:34,999 - INFO - joeynmt.training - Epoch   7, Step:    24700, Batch Loss:     1.572715, Batch Acc: 0.545630, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 10:37:23,522 - INFO - joeynmt.training - Epoch   7, Step:    24800, Batch Loss:     1.370855, Batch Acc: 0.538343, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 10:38:12,697 - INFO - joeynmt.training - Epoch   7, Step:    24900, Batch Loss:     2.063512, Batch Acc: 0.536017, Tokens per Sec:      334, Lr: 0.000200
2024-02-21 10:39:00,742 - INFO - joeynmt.training - Epoch   7, Step:    25000, Batch Loss:     1.316075, Batch Acc: 0.542353, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 10:39:00,743 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:44<00:00,  7.77it/s]
2024-02-21 10:39:45,919 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  45.15, loss:   1.41, ppl:   4.09, acc:   0.50, generation: 44.5208[sec], evaluation: 0.6309[sec]
2024-02-21 10:39:45,920 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 10:39:50,068 - INFO - joeynmt.helpers - delete experiment/24000.ckpt
2024-02-21 10:39:50,140 - INFO - joeynmt.training - Example #0
2024-02-21 10:39:50,148 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 10:39:50,150 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 10:39:50,153 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S26606503x504S26612468x505S2fb04492x561S20500495x493S15a50501x493S15a58486x493
2024-02-21 10:39:50,155 - INFO - joeynmt.training - Example #1
2024-02-21 10:39:50,161 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 10:39:50,163 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 10:39:50,165 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S1000a473x491S10002501x492S2ea00508x504S2ea4c476x504S2fd04489x560
2024-02-21 10:39:50,167 - INFO - joeynmt.training - Example #2
2024-02-21 10:39:50,173 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 10:39:50,175 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 10:39:50,179 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x449S2ff00504x449S35d14453x469S1ce10465x449S1ce18431x469S20500453x459S22b04461x480S22b04461x508S22b14431x504S1ce10539x478S1ce18504x478S2fd04522x547
2024-02-21 10:39:50,182 - INFO - joeynmt.training - Example #3
2024-02-21 10:39:50,188 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 10:39:50,191 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 10:39:50,194 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006469x475S35d10482x497S10010502x475S20500507x469S20500507x470S22a04510x504
2024-02-21 10:40:38,747 - INFO - joeynmt.training - Epoch   7, Step:    25100, Batch Loss:     1.403713, Batch Acc: 0.542128, Tokens per Sec:      317, Lr: 0.000200
2024-02-21 10:41:27,367 - INFO - joeynmt.training - Epoch   7, Step:    25200, Batch Loss:     1.545383, Batch Acc: 0.547319, Tokens per Sec:      351, Lr: 0.000200
2024-02-21 10:42:16,798 - INFO - joeynmt.training - Epoch   7, Step:    25300, Batch Loss:     1.250989, Batch Acc: 0.540856, Tokens per Sec:      342, Lr: 0.000200
2024-02-21 10:43:04,417 - INFO - joeynmt.training - Epoch   7, Step:    25400, Batch Loss:     1.353921, Batch Acc: 0.530417, Tokens per Sec:      367, Lr: 0.000200
2024-02-21 10:43:52,733 - INFO - joeynmt.training - Epoch   7, Step:    25500, Batch Loss:     1.159559, Batch Acc: 0.535846, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 10:44:41,253 - INFO - joeynmt.training - Epoch   7, Step:    25600, Batch Loss:     1.252500, Batch Acc: 0.538905, Tokens per Sec:      358, Lr: 0.000200
2024-02-21 10:45:29,280 - INFO - joeynmt.training - Epoch   7, Step:    25700, Batch Loss:     1.289321, Batch Acc: 0.539614, Tokens per Sec:      367, Lr: 0.000200
2024-02-21 10:46:17,546 - INFO - joeynmt.training - Epoch   7, Step:    25800, Batch Loss:     1.086282, Batch Acc: 0.547023, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 10:47:05,078 - INFO - joeynmt.training - Epoch   7, Step:    25900, Batch Loss:     0.988833, Batch Acc: 0.549165, Tokens per Sec:      353, Lr: 0.000200
2024-02-21 10:47:53,229 - INFO - joeynmt.training - Epoch   7, Step:    26000, Batch Loss:     1.169443, Batch Acc: 0.524412, Tokens per Sec:      353, Lr: 0.000200
2024-02-21 10:47:53,230 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:45<00:00,  7.68it/s]
2024-02-21 10:48:39,335 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  45.22, loss:   1.40, ppl:   4.05, acc:   0.50, generation: 45.0412[sec], evaluation: 1.0222[sec]
2024-02-21 10:48:39,335 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 10:48:42,283 - INFO - joeynmt.helpers - delete experiment/20000.ckpt
2024-02-21 10:48:42,326 - INFO - joeynmt.training - Example #0
2024-02-21 10:48:42,328 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 10:48:42,328 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 10:48:42,328 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S26606503x476S26612469x476S2fb04492x559S20500495x478S2fb04492x559S22204483x503S22204505x503S22204483x503S22204483x503S22204483x503S22204483x503
2024-02-21 10:48:42,328 - INFO - joeynmt.training - Example #1
2024-02-21 10:48:42,329 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 10:48:42,329 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 10:48:42,329 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S20306483x492S2030e483x492S26506507x493S26512478x493S2fb04492x559
2024-02-21 10:48:42,329 - INFO - joeynmt.training - Example #2
2024-02-21 10:48:42,329 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 10:48:42,329 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 10:48:42,330 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00436x457S2ff00509x457S35d14447x477S1ce10463x494S2e500456x517S15a18509x517S2f900506x536S1ce10532x500S20500521x503S22a04547x524
2024-02-21 10:48:42,330 - INFO - joeynmt.training - Example #3
2024-02-21 10:48:42,330 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 10:48:42,330 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 10:48:42,330 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006469x474S35d14482x494S10000507x482S20500507x474S20500507x474S26a04507x506
2024-02-21 10:49:31,484 - INFO - joeynmt.training - Epoch   7, Step:    26100, Batch Loss:     1.621220, Batch Acc: 0.534468, Tokens per Sec:      321, Lr: 0.000200
2024-02-21 10:50:18,391 - INFO - joeynmt.training - Epoch   7, Step:    26200, Batch Loss:     1.161499, Batch Acc: 0.540438, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 10:51:06,656 - INFO - joeynmt.training - Epoch   7, Step:    26300, Batch Loss:     0.959047, Batch Acc: 0.540080, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 10:51:54,887 - INFO - joeynmt.training - Epoch   7, Step:    26400, Batch Loss:     1.279589, Batch Acc: 0.533735, Tokens per Sec:      361, Lr: 0.000200
2024-02-21 10:52:42,263 - INFO - joeynmt.training - Epoch   7, Step:    26500, Batch Loss:     1.348271, Batch Acc: 0.537560, Tokens per Sec:      353, Lr: 0.000200
2024-02-21 10:53:31,324 - INFO - joeynmt.training - Epoch   7, Step:    26600, Batch Loss:     1.119485, Batch Acc: 0.549305, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 10:54:19,028 - INFO - joeynmt.training - Epoch   7, Step:    26700, Batch Loss:     1.380973, Batch Acc: 0.547118, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 10:55:07,073 - INFO - joeynmt.training - Epoch   7, Step:    26800, Batch Loss:     1.323403, Batch Acc: 0.537124, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 10:55:54,144 - INFO - joeynmt.training - Epoch   7, Step:    26900, Batch Loss:     1.285004, Batch Acc: 0.541295, Tokens per Sec:      369, Lr: 0.000200
2024-02-21 10:56:42,263 - INFO - joeynmt.training - Epoch   7, Step:    27000, Batch Loss:     1.332283, Batch Acc: 0.545460, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 10:56:42,263 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:47<00:00,  7.31it/s]
2024-02-21 10:57:30,220 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  45.97, loss:   1.40, ppl:   4.04, acc:   0.50, generation: 47.3010[sec], evaluation: 0.6348[sec]
2024-02-21 10:57:30,221 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 10:57:31,600 - INFO - joeynmt.helpers - delete experiment/25000.ckpt
2024-02-21 10:57:31,649 - INFO - joeynmt.training - Example #0
2024-02-21 10:57:31,651 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 10:57:31,651 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 10:57:31,651 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S26606503x516S26612469x516S2fb04492x561S20350501x483S20358483x483
2024-02-21 10:57:31,651 - INFO - joeynmt.training - Example #1
2024-02-21 10:57:31,651 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 10:57:31,651 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 10:57:31,652 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S1ea0e501x474S1ea06476x474S2fb04492x561S2a208501x504S2a210476x504
2024-02-21 10:57:31,652 - INFO - joeynmt.training - Example #2
2024-02-21 10:57:31,652 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 10:57:31,652 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 10:57:31,653 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00436x450S2ff00509x450S30007509x450S35d14448x470S1ce10450x490S1ce48499x490S20500525x503S2f900509x544S28706547x515S28712487x516
2024-02-21 10:57:31,653 - INFO - joeynmt.training - Example #3
2024-02-21 10:57:31,653 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 10:57:31,653 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 10:57:31,653 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006469x475S35d10482x497S10010505x475S20500502x475S20500502x477S26a04505x503
2024-02-21 10:58:20,210 - INFO - joeynmt.training - Epoch   7, Step:    27100, Batch Loss:     1.245193, Batch Acc: 0.545515, Tokens per Sec:      333, Lr: 0.000200
2024-02-21 10:59:08,150 - INFO - joeynmt.training - Epoch   7, Step:    27200, Batch Loss:     1.261384, Batch Acc: 0.543073, Tokens per Sec:      358, Lr: 0.000200
2024-02-21 10:59:54,911 - INFO - joeynmt.training - Epoch   7, Step:    27300, Batch Loss:     1.185592, Batch Acc: 0.543250, Tokens per Sec:      366, Lr: 0.000200
2024-02-21 11:00:43,021 - INFO - joeynmt.training - Epoch   7, Step:    27400, Batch Loss:     1.350374, Batch Acc: 0.538366, Tokens per Sec:      369, Lr: 0.000200
2024-02-21 11:01:32,176 - INFO - joeynmt.training - Epoch   7, Step:    27500, Batch Loss:     1.239847, Batch Acc: 0.548940, Tokens per Sec:      355, Lr: 0.000200
2024-02-21 11:02:07,259 - INFO - joeynmt.training - Epoch   7: total training loss 4873.60, num seqs 15756, num tokens 672796
2024-02-21 11:02:07,260 - INFO - joeynmt.training - EPOCH 8
2024-02-21 11:02:20,020 - INFO - joeynmt.training - Epoch   8, Step:    27600, Batch Loss:     1.040824, Batch Acc: 0.547025, Tokens per Sec:      336, Lr: 0.000200
2024-02-21 11:03:07,343 - INFO - joeynmt.training - Epoch   8, Step:    27700, Batch Loss:     1.115011, Batch Acc: 0.555907, Tokens per Sec:      367, Lr: 0.000200
2024-02-21 11:03:54,946 - INFO - joeynmt.training - Epoch   8, Step:    27800, Batch Loss:     1.284832, Batch Acc: 0.568903, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 11:04:42,598 - INFO - joeynmt.training - Epoch   8, Step:    27900, Batch Loss:     1.082459, Batch Acc: 0.562390, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 11:05:31,277 - INFO - joeynmt.training - Epoch   8, Step:    28000, Batch Loss:     1.237499, Batch Acc: 0.561855, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 11:05:31,278 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:46<00:00,  7.47it/s]
2024-02-21 11:06:18,245 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  46.61, loss:   1.40, ppl:   4.06, acc:   0.50, generation: 46.3115[sec], evaluation: 0.6319[sec]
2024-02-21 11:06:18,246 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 11:06:21,524 - INFO - joeynmt.helpers - delete experiment/26000.ckpt
2024-02-21 11:06:21,596 - INFO - joeynmt.training - Example #0
2024-02-21 11:06:21,598 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 11:06:21,598 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 11:06:21,599 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S22b06503x513S22b12467x513S2fb04492x561S22104503x508S22104483x508S22104483x508S22104503x508
2024-02-21 11:06:21,599 - INFO - joeynmt.training - Example #1
2024-02-21 11:06:21,599 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 11:06:21,599 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 11:06:21,600 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S22b06503x513S22b12467x513S2fb04492x561S10002501x483S1000a473x500
2024-02-21 11:06:21,600 - INFO - joeynmt.training - Example #2
2024-02-21 11:06:21,600 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 11:06:21,600 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 11:06:21,601 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00436x450S2ff00509x450S30007509x450S35d14447x470S1ce10449x490S1ce18499x490S2f900497x540S22a02541x527S18210458x498S20500449x498S26500458x498S26500462x498S26500475x498
2024-02-21 11:06:21,601 - INFO - joeynmt.training - Example #3
2024-02-21 11:06:21,601 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 11:06:21,601 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 11:06:21,601 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006473x475S35d10486x493S10010500x475S20500503x475S20500506x475S26a04503x503
2024-02-21 11:07:08,955 - INFO - joeynmt.training - Epoch   8, Step:    28100, Batch Loss:     1.361086, Batch Acc: 0.560226, Tokens per Sec:      331, Lr: 0.000200
2024-02-21 11:07:57,402 - INFO - joeynmt.training - Epoch   8, Step:    28200, Batch Loss:     0.841342, Batch Acc: 0.561253, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 11:08:46,445 - INFO - joeynmt.training - Epoch   8, Step:    28300, Batch Loss:     1.324897, Batch Acc: 0.550438, Tokens per Sec:      349, Lr: 0.000200
2024-02-21 11:09:33,741 - INFO - joeynmt.training - Epoch   8, Step:    28400, Batch Loss:     0.999066, Batch Acc: 0.564858, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 11:10:20,835 - INFO - joeynmt.training - Epoch   8, Step:    28500, Batch Loss:     1.227414, Batch Acc: 0.553029, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 11:11:08,418 - INFO - joeynmt.training - Epoch   8, Step:    28600, Batch Loss:     1.093977, Batch Acc: 0.566847, Tokens per Sec:      351, Lr: 0.000200
2024-02-21 11:11:55,986 - INFO - joeynmt.training - Epoch   8, Step:    28700, Batch Loss:     1.217196, Batch Acc: 0.558305, Tokens per Sec:      340, Lr: 0.000200
2024-02-21 11:12:43,883 - INFO - joeynmt.training - Epoch   8, Step:    28800, Batch Loss:     1.014495, Batch Acc: 0.563270, Tokens per Sec:      342, Lr: 0.000200
2024-02-21 11:13:31,790 - INFO - joeynmt.training - Epoch   8, Step:    28900, Batch Loss:     1.129664, Batch Acc: 0.554490, Tokens per Sec:      361, Lr: 0.000200
2024-02-21 11:14:19,699 - INFO - joeynmt.training - Epoch   8, Step:    29000, Batch Loss:     1.052266, Batch Acc: 0.558632, Tokens per Sec:      349, Lr: 0.000200
2024-02-21 11:14:19,699 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:45<00:00,  7.65it/s]
2024-02-21 11:15:05,890 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  46.39, loss:   1.40, ppl:   4.05, acc:   0.50, generation: 45.2537[sec], evaluation: 0.9133[sec]
2024-02-21 11:15:07,042 - INFO - joeynmt.helpers - delete experiment/27000.ckpt
2024-02-21 11:15:07,107 - INFO - joeynmt.training - Example #0
2024-02-21 11:15:07,108 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 11:15:07,108 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 11:15:07,108 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x439S35d14495x459S20350501x493S20358483x493S22a04507x507S22a14480x507S22a14480x507S22a14480x507S22a14480x507S2fc04492x551
2024-02-21 11:15:07,108 - INFO - joeynmt.training - Example #1
2024-02-21 11:15:07,109 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 11:15:07,109 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 11:15:07,109 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S11002503x476S1100a467x476S2fb04492x560S22f02508x511S22f16467x511
2024-02-21 11:15:07,109 - INFO - joeynmt.training - Example #2
2024-02-21 11:15:07,110 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 11:15:07,110 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 11:15:07,110 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00439x451S2ff00512x451S35d14452x471S14448500x494S14440532x494S20500525x510S2f900510x525S22a02547x523S14402459x491S14400455x491S14400455x491S26b04455x520
2024-02-21 11:15:07,110 - INFO - joeynmt.training - Example #3
2024-02-21 11:15:07,110 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 11:15:07,110 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 11:15:07,110 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006469x475S35d14482x497S10000505x475S20500505x475S20500505x475S26a04505x500
2024-02-21 11:15:54,346 - INFO - joeynmt.training - Epoch   8, Step:    29100, Batch Loss:     0.976394, Batch Acc: 0.562190, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 11:16:43,463 - INFO - joeynmt.training - Epoch   8, Step:    29200, Batch Loss:     0.977930, Batch Acc: 0.548894, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 11:17:31,409 - INFO - joeynmt.training - Epoch   8, Step:    29300, Batch Loss:     1.203817, Batch Acc: 0.562416, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 11:18:18,632 - INFO - joeynmt.training - Epoch   8, Step:    29400, Batch Loss:     1.148986, Batch Acc: 0.547532, Tokens per Sec:      375, Lr: 0.000200
2024-02-21 11:19:06,334 - INFO - joeynmt.training - Epoch   8, Step:    29500, Batch Loss:     1.408291, Batch Acc: 0.558948, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 11:19:55,429 - INFO - joeynmt.training - Epoch   8, Step:    29600, Batch Loss:     1.100671, Batch Acc: 0.557221, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 11:20:43,419 - INFO - joeynmt.training - Epoch   8, Step:    29700, Batch Loss:     1.016995, Batch Acc: 0.562259, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 11:21:30,460 - INFO - joeynmt.training - Epoch   8, Step:    29800, Batch Loss:     1.264637, Batch Acc: 0.557143, Tokens per Sec:      369, Lr: 0.000200
2024-02-21 11:22:17,744 - INFO - joeynmt.training - Epoch   8, Step:    29900, Batch Loss:     1.058431, Batch Acc: 0.552875, Tokens per Sec:      377, Lr: 0.000200
2024-02-21 11:23:05,681 - INFO - joeynmt.training - Epoch   8, Step:    30000, Batch Loss:     0.794943, Batch Acc: 0.556784, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 11:23:05,682 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:49<00:00,  7.03it/s]
2024-02-21 11:23:55,570 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  45.11, loss:   1.39, ppl:   4.02, acc:   0.50, generation: 49.2045[sec], evaluation: 0.6595[sec]
2024-02-21 11:23:55,572 - INFO - joeynmt.training - Example #0
2024-02-21 11:23:55,572 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 11:23:55,572 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 11:23:55,572 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S26606501x520S26612469x520S20500495x493S2fb04492x561S20350502x483S20350483x483S22200483x483S22200483x483S22200483x483S22200483x483S22200483x483S22200483x498S22200478x498
2024-02-21 11:23:55,573 - INFO - joeynmt.training - Example #1
2024-02-21 11:23:55,573 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 11:23:55,573 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 11:23:55,573 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S10002501x476S1000a476x476S2ea00509x495S2ea4c476x495S2fd04489x560
2024-02-21 11:23:55,573 - INFO - joeynmt.training - Example #2
2024-02-21 11:23:55,574 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 11:23:55,574 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 11:23:55,574 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00436x457S2ff00509x457S35d14448x477S21100436x506S2e500456x515S18510537x494S18518498x494S2fb04516x538
2024-02-21 11:23:55,574 - INFO - joeynmt.training - Example #3
2024-02-21 11:23:55,575 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 11:23:55,575 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 11:23:55,575 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006471x470S35d10482x488S10010509x488S21100509x472S26a04509x509
2024-02-21 11:24:43,742 - INFO - joeynmt.training - Epoch   8, Step:    30100, Batch Loss:     1.176097, Batch Acc: 0.571239, Tokens per Sec:      344, Lr: 0.000200
2024-02-21 11:25:30,717 - INFO - joeynmt.training - Epoch   8, Step:    30200, Batch Loss:     1.164163, Batch Acc: 0.555595, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 11:26:18,998 - INFO - joeynmt.training - Epoch   8, Step:    30300, Batch Loss:     1.811163, Batch Acc: 0.557484, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 11:27:06,801 - INFO - joeynmt.training - Epoch   8, Step:    30400, Batch Loss:     0.992977, Batch Acc: 0.555154, Tokens per Sec:      364, Lr: 0.000200
2024-02-21 11:27:55,051 - INFO - joeynmt.training - Epoch   8, Step:    30500, Batch Loss:     1.057405, Batch Acc: 0.562090, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 11:28:42,182 - INFO - joeynmt.training - Epoch   8, Step:    30600, Batch Loss:     1.022640, Batch Acc: 0.562170, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 11:29:30,325 - INFO - joeynmt.training - Epoch   8, Step:    30700, Batch Loss:     1.136857, Batch Acc: 0.559617, Tokens per Sec:      358, Lr: 0.000200
2024-02-21 11:30:18,077 - INFO - joeynmt.training - Epoch   8, Step:    30800, Batch Loss:     1.090630, Batch Acc: 0.553988, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 11:31:06,188 - INFO - joeynmt.training - Epoch   8, Step:    30900, Batch Loss:     1.036433, Batch Acc: 0.563283, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 11:31:53,925 - INFO - joeynmt.training - Epoch   8, Step:    31000, Batch Loss:     1.102071, Batch Acc: 0.557683, Tokens per Sec:      365, Lr: 0.000200
2024-02-21 11:31:53,926 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:47<00:00,  7.26it/s]
2024-02-21 11:32:42,246 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  44.91, loss:   1.39, ppl:   4.02, acc:   0.50, generation: 47.6501[sec], evaluation: 0.6453[sec]
2024-02-21 11:32:42,247 - INFO - joeynmt.training - Example #0
2024-02-21 11:32:42,248 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 11:32:42,248 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 11:32:42,248 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04493x561S26606501x474S26612469x474S26606502x474S26612467x474S26606501x474S26612469x475S22620502x472S22620502x472S22620502x472S22620502x472S22620469x472
2024-02-21 11:32:42,248 - INFO - joeynmt.training - Example #1
2024-02-21 11:32:42,248 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 11:32:42,248 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 11:32:42,248 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S1ea40501x473S1ea48476x473S2fb04493x560S22f02510x511S22f16476x511
2024-02-21 11:32:42,249 - INFO - joeynmt.training - Example #2
2024-02-21 11:32:42,249 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 11:32:42,249 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 11:32:42,249 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x440S2ff00513x440S35d14453x460S1ce10464x477S2e500460x510S15310537x487S15318507x487S2fd04516x555S24e30537x477S24e48506x477
2024-02-21 11:32:42,249 - INFO - joeynmt.training - Example #3
2024-02-21 11:32:42,250 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 11:32:42,250 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 11:32:42,250 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00474x465S35d14487x485S10011498x486S2b704502x516
2024-02-21 11:33:30,337 - INFO - joeynmt.training - Epoch   8, Step:    31100, Batch Loss:     0.990479, Batch Acc: 0.566538, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 11:34:18,082 - INFO - joeynmt.training - Epoch   8, Step:    31200, Batch Loss:     1.050672, Batch Acc: 0.559113, Tokens per Sec:      368, Lr: 0.000200
2024-02-21 11:35:07,920 - INFO - joeynmt.training - Epoch   8, Step:    31300, Batch Loss:     0.858970, Batch Acc: 0.565067, Tokens per Sec:      348, Lr: 0.000200
2024-02-21 11:35:56,213 - INFO - joeynmt.training - Epoch   8, Step:    31400, Batch Loss:     1.159045, Batch Acc: 0.552222, Tokens per Sec:      369, Lr: 0.000200
2024-02-21 11:36:44,502 - INFO - joeynmt.training - Epoch   8, Step:    31500, Batch Loss:     1.135210, Batch Acc: 0.566959, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 11:36:49,802 - INFO - joeynmt.training - Epoch   8: total training loss 4647.87, num seqs 15756, num tokens 672796
2024-02-21 11:36:49,803 - INFO - joeynmt.training - EPOCH 9
2024-02-21 11:37:31,568 - INFO - joeynmt.training - Epoch   9, Step:    31600, Batch Loss:     0.897229, Batch Acc: 0.588092, Tokens per Sec:      364, Lr: 0.000200
2024-02-21 11:38:19,876 - INFO - joeynmt.training - Epoch   9, Step:    31700, Batch Loss:     0.966904, Batch Acc: 0.584836, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 11:39:08,959 - INFO - joeynmt.training - Epoch   9, Step:    31800, Batch Loss:     1.261140, Batch Acc: 0.583691, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 11:39:56,065 - INFO - joeynmt.training - Epoch   9, Step:    31900, Batch Loss:     1.383376, Batch Acc: 0.585758, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 11:40:43,304 - INFO - joeynmt.training - Epoch   9, Step:    32000, Batch Loss:     0.960115, Batch Acc: 0.577887, Tokens per Sec:      353, Lr: 0.000200
2024-02-21 11:40:43,305 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:44<00:00,  7.73it/s]
2024-02-21 11:41:28,674 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  46.02, loss:   1.41, ppl:   4.09, acc:   0.50, generation: 44.7652[sec], evaluation: 0.5824[sec]
2024-02-21 11:41:28,675 - INFO - joeynmt.training - Example #0
2024-02-21 11:41:28,676 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 11:41:28,676 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 11:41:28,676 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x560S26606503x492S26612469x492S20500495x493S22200505x493S22200484x493S22200484x493S20350484x493S20350484x493
2024-02-21 11:41:28,676 - INFO - joeynmt.training - Example #1
2024-02-21 11:41:28,676 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 11:41:28,676 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 11:41:28,676 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S10002504x493S1000a469x493S26500511x493S26510478x493S2fb04492x560
2024-02-21 11:41:28,677 - INFO - joeynmt.training - Example #2
2024-02-21 11:41:28,677 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 11:41:28,677 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 11:41:28,677 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00509x437S30006437x437S35d14450x457S1ce10459x473S2e500453x499S15a10532x477S15a18500x477S23100532x504S2311c494x509S2fd04515x558
2024-02-21 11:41:28,677 - INFO - joeynmt.training - Example #3
2024-02-21 11:41:28,678 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 11:41:28,678 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 11:41:28,678 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006469x474S35d14482x497S10011498x488S21100506x467S21100506x467S26a04505x500
2024-02-21 11:42:17,777 - INFO - joeynmt.training - Epoch   9, Step:    32100, Batch Loss:     1.051387, Batch Acc: 0.575294, Tokens per Sec:      331, Lr: 0.000200
2024-02-21 11:43:04,924 - INFO - joeynmt.training - Epoch   9, Step:    32200, Batch Loss:     1.061636, Batch Acc: 0.579837, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 11:43:53,210 - INFO - joeynmt.training - Epoch   9, Step:    32300, Batch Loss:     1.215723, Batch Acc: 0.580563, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 11:44:41,685 - INFO - joeynmt.training - Epoch   9, Step:    32400, Batch Loss:     1.302497, Batch Acc: 0.572212, Tokens per Sec:      369, Lr: 0.000200
2024-02-21 11:45:29,845 - INFO - joeynmt.training - Epoch   9, Step:    32500, Batch Loss:     1.194144, Batch Acc: 0.575870, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 11:46:17,873 - INFO - joeynmt.training - Epoch   9, Step:    32600, Batch Loss:     1.292230, Batch Acc: 0.579187, Tokens per Sec:      366, Lr: 0.000200
2024-02-21 11:47:06,007 - INFO - joeynmt.training - Epoch   9, Step:    32700, Batch Loss:     1.033767, Batch Acc: 0.578475, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 11:47:54,082 - INFO - joeynmt.training - Epoch   9, Step:    32800, Batch Loss:     1.094743, Batch Acc: 0.574845, Tokens per Sec:      365, Lr: 0.000200
2024-02-21 11:48:42,441 - INFO - joeynmt.training - Epoch   9, Step:    32900, Batch Loss:     1.316842, Batch Acc: 0.576498, Tokens per Sec:      355, Lr: 0.000200
2024-02-21 11:49:30,645 - INFO - joeynmt.training - Epoch   9, Step:    33000, Batch Loss:     1.126085, Batch Acc: 0.584310, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 11:49:30,646 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:50<00:00,  6.81it/s]
2024-02-21 11:50:22,379 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  48.77, loss:   1.40, ppl:   4.05, acc:   0.51, generation: 50.8425[sec], evaluation: 0.8682[sec]
2024-02-21 11:50:22,380 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 11:50:25,343 - INFO - joeynmt.helpers - delete experiment/29000.ckpt
2024-02-21 11:50:25,383 - INFO - joeynmt.training - Example #0
2024-02-21 11:50:25,384 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 11:50:25,384 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 11:50:25,384 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S36520495x457S14c50501x479S14c58476x479S22520502x472S22520476x472S22520502x476S22520476x476S2fc04492x554
2024-02-21 11:50:25,385 - INFO - joeynmt.training - Example #1
2024-02-21 11:50:25,385 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 11:50:25,385 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 11:50:25,385 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S10002501x479S1000a476x479S2ea34509x508S2ea4c476x508S2ea30508x508S2ea10480x508S2fd04489x560
2024-02-21 11:50:25,385 - INFO - joeynmt.training - Example #2
2024-02-21 11:50:25,386 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 11:50:25,386 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 11:50:25,386 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00436x457S2ff00509x457S35d14448x477S1ce10461x477S2e500447x504S15a18509x501S2f900498x528S15a11527x501S20500525x502S23002547x517
2024-02-21 11:50:25,386 - INFO - joeynmt.training - Example #3
2024-02-21 11:50:25,386 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 11:50:25,386 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 11:50:25,387 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x470S35d10487x490S10010502x488S20500502x485S20500502x485S26504509x509
2024-02-21 11:51:13,739 - INFO - joeynmt.training - Epoch   9, Step:    33100, Batch Loss:     1.207163, Batch Acc: 0.588793, Tokens per Sec:      339, Lr: 0.000200
2024-02-21 11:52:01,494 - INFO - joeynmt.training - Epoch   9, Step:    33200, Batch Loss:     1.291778, Batch Acc: 0.579399, Tokens per Sec:      371, Lr: 0.000200
2024-02-21 11:52:49,710 - INFO - joeynmt.training - Epoch   9, Step:    33300, Batch Loss:     1.153197, Batch Acc: 0.572483, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 11:53:39,033 - INFO - joeynmt.training - Epoch   9, Step:    33400, Batch Loss:     1.262394, Batch Acc: 0.584174, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 11:54:26,924 - INFO - joeynmt.training - Epoch   9, Step:    33500, Batch Loss:     1.481878, Batch Acc: 0.579395, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 11:55:14,895 - INFO - joeynmt.training - Epoch   9, Step:    33600, Batch Loss:     0.864019, Batch Acc: 0.584980, Tokens per Sec:      361, Lr: 0.000200
2024-02-21 11:56:02,875 - INFO - joeynmt.training - Epoch   9, Step:    33700, Batch Loss:     1.673772, Batch Acc: 0.582638, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 11:56:52,223 - INFO - joeynmt.training - Epoch   9, Step:    33800, Batch Loss:     1.280362, Batch Acc: 0.577565, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 11:57:39,761 - INFO - joeynmt.training - Epoch   9, Step:    33900, Batch Loss:     0.990184, Batch Acc: 0.584228, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 11:58:27,099 - INFO - joeynmt.training - Epoch   9, Step:    34000, Batch Loss:     1.049980, Batch Acc: 0.568919, Tokens per Sec:      355, Lr: 0.000200
2024-02-21 11:58:27,099 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:45<00:00,  7.68it/s]
2024-02-21 11:59:12,767 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  44.93, loss:   1.40, ppl:   4.06, acc:   0.51, generation: 45.0267[sec], evaluation: 0.6183[sec]
2024-02-21 11:59:12,768 - INFO - joeynmt.training - Example #0
2024-02-21 11:59:12,769 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 11:59:12,769 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 11:59:12,769 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S11e50503x502S11e58474x502S26507507x473S26511473x472S2fb04492x561
2024-02-21 11:59:12,769 - INFO - joeynmt.training - Example #1
2024-02-21 11:59:12,770 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 11:59:12,770 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 11:59:12,770 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S10002507x496S1000a469x497S2ea00508x497S2ea4c478x497S2fd04489x560
2024-02-21 11:59:12,770 - INFO - joeynmt.training - Example #2
2024-02-21 11:59:12,771 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 11:59:12,771 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 11:59:12,771 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00436x450S2ff00509x450S35d14449x470S1ce10461x471S2e500452x510S18510532x481S18518499x481S2fb04516x546
2024-02-21 11:59:12,771 - INFO - joeynmt.training - Example #3
2024-02-21 11:59:12,771 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 11:59:12,771 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 11:59:12,771 - INFO - joeynmt.training - 	Hypothesis: M500x500S30007469x479S35d14482x502S10011498x488S20500482x477S26a04507x507
2024-02-21 12:00:01,801 - INFO - joeynmt.training - Epoch   9, Step:    34100, Batch Loss:     1.359024, Batch Acc: 0.578424, Tokens per Sec:      351, Lr: 0.000200
2024-02-21 12:00:50,622 - INFO - joeynmt.training - Epoch   9, Step:    34200, Batch Loss:     1.079148, Batch Acc: 0.584804, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 12:01:39,275 - INFO - joeynmt.training - Epoch   9, Step:    34300, Batch Loss:     0.960059, Batch Acc: 0.579548, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 12:02:27,591 - INFO - joeynmt.training - Epoch   9, Step:    34400, Batch Loss:     1.313025, Batch Acc: 0.581704, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 12:03:15,927 - INFO - joeynmt.training - Epoch   9, Step:    34500, Batch Loss:     0.788214, Batch Acc: 0.576321, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 12:04:04,352 - INFO - joeynmt.training - Epoch   9, Step:    34600, Batch Loss:     0.902401, Batch Acc: 0.570714, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 12:04:52,953 - INFO - joeynmt.training - Epoch   9, Step:    34700, Batch Loss:     1.173633, Batch Acc: 0.581448, Tokens per Sec:      348, Lr: 0.000200
2024-02-21 12:05:41,284 - INFO - joeynmt.training - Epoch   9, Step:    34800, Batch Loss:     1.565938, Batch Acc: 0.582298, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 12:06:29,358 - INFO - joeynmt.training - Epoch   9, Step:    34900, Batch Loss:     1.418463, Batch Acc: 0.576960, Tokens per Sec:      342, Lr: 0.000200
2024-02-21 12:07:16,297 - INFO - joeynmt.training - Epoch   9, Step:    35000, Batch Loss:     1.588577, Batch Acc: 0.575335, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 12:07:16,297 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:51<00:00,  6.75it/s]
2024-02-21 12:08:08,437 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  48.34, loss:   1.39, ppl:   4.00, acc:   0.51, generation: 51.2791[sec], evaluation: 0.8364[sec]
2024-02-21 12:08:13,467 - INFO - joeynmt.helpers - delete experiment/28000.ckpt
2024-02-21 12:08:13,516 - INFO - joeynmt.training - Example #0
2024-02-21 12:08:13,517 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 12:08:13,517 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 12:08:13,517 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S26606503x505S26612471x505S2fb04492x561S20500495x472S18250501x505S18258476x502
2024-02-21 12:08:13,517 - INFO - joeynmt.training - Example #1
2024-02-21 12:08:13,518 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 12:08:13,518 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 12:08:13,518 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S10002507x492S1000a469x492S2ea00508x508S2ea4c478x508S2fd04489x560
2024-02-21 12:08:13,518 - INFO - joeynmt.training - Example #2
2024-02-21 12:08:13,519 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 12:08:13,519 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 12:08:13,519 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00441x441S2ff00514x441S34c10454x461S1ce10463x471S2e500454x506S15a18509x492S2f900506x509S20500525x509S1ce10527x478S1ce10532x478S20500518x509S22b02529x514
2024-02-21 12:08:13,519 - INFO - joeynmt.training - Example #3
2024-02-21 12:08:13,520 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 12:08:13,520 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 12:08:13,520 - INFO - joeynmt.training - 	Hypothesis: M500x500S30004474x472S35d10487x493S10011498x488S20500506x485S26a04501x515
2024-02-21 12:09:02,329 - INFO - joeynmt.training - Epoch   9, Step:    35100, Batch Loss:     1.168606, Batch Acc: 0.566991, Tokens per Sec:      332, Lr: 0.000200
2024-02-21 12:09:49,755 - INFO - joeynmt.training - Epoch   9, Step:    35200, Batch Loss:     1.104730, Batch Acc: 0.572548, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 12:10:38,327 - INFO - joeynmt.training - Epoch   9, Step:    35300, Batch Loss:     0.904028, Batch Acc: 0.572730, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 12:11:27,733 - INFO - joeynmt.training - Epoch   9, Step:    35400, Batch Loss:     1.297091, Batch Acc: 0.571546, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 12:11:52,191 - INFO - joeynmt.training - Epoch   9: total training loss 4434.27, num seqs 15756, num tokens 672796
2024-02-21 12:11:52,191 - INFO - joeynmt.training - EPOCH 10
2024-02-21 12:12:15,740 - INFO - joeynmt.training - Epoch  10, Step:    35500, Batch Loss:     1.211486, Batch Acc: 0.582734, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 12:13:02,926 - INFO - joeynmt.training - Epoch  10, Step:    35600, Batch Loss:     1.221213, Batch Acc: 0.601250, Tokens per Sec:      373, Lr: 0.000200
2024-02-21 12:13:50,783 - INFO - joeynmt.training - Epoch  10, Step:    35700, Batch Loss:     0.806501, Batch Acc: 0.602515, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 12:14:39,932 - INFO - joeynmt.training - Epoch  10, Step:    35800, Batch Loss:     1.106696, Batch Acc: 0.602842, Tokens per Sec:      336, Lr: 0.000200
2024-02-21 12:15:27,873 - INFO - joeynmt.training - Epoch  10, Step:    35900, Batch Loss:     1.086634, Batch Acc: 0.595606, Tokens per Sec:      351, Lr: 0.000200
2024-02-21 12:16:14,976 - INFO - joeynmt.training - Epoch  10, Step:    36000, Batch Loss:     0.982736, Batch Acc: 0.604898, Tokens per Sec:      364, Lr: 0.000200
2024-02-21 12:16:14,976 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:47<00:00,  7.33it/s]
2024-02-21 12:17:02,848 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  46.54, loss:   1.40, ppl:   4.05, acc:   0.51, generation: 47.2124[sec], evaluation: 0.6369[sec]
2024-02-21 12:17:02,849 - INFO - joeynmt.training - Example #0
2024-02-21 12:17:02,850 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 12:17:02,850 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 12:17:02,850 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x560S26606501x482S26612469x482S20500495x472S22620501x472S22620476x472S22620502x472S22620469x499S22620502x499S22620502x499
2024-02-21 12:17:02,850 - INFO - joeynmt.training - Example #1
2024-02-21 12:17:02,851 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 12:17:02,851 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 12:17:02,851 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S10002502x482S1000a469x482S10000540x482S10008446x482S2ea00530x495S2ea4c454x507S2fd04489x560
2024-02-21 12:17:02,851 - INFO - joeynmt.training - Example #2
2024-02-21 12:17:02,852 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 12:17:02,852 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 12:17:02,852 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00436x450S2ff00509x450S34710447x472S1ce10468x470S2e500453x509S15a18509x492S2f900499x525S15a11527x486S20500518x516S22a02532x522
2024-02-21 12:17:02,852 - INFO - joeynmt.training - Example #3
2024-02-21 12:17:02,852 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 12:17:02,852 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 12:17:02,852 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x472S34c10489x492S10010507x481S20500507x472S26a04503x503
2024-02-21 12:17:51,393 - INFO - joeynmt.training - Epoch  10, Step:    36100, Batch Loss:     1.071494, Batch Acc: 0.597963, Tokens per Sec:      344, Lr: 0.000200
2024-02-21 12:18:40,868 - INFO - joeynmt.training - Epoch  10, Step:    36200, Batch Loss:     1.002514, Batch Acc: 0.596948, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 12:19:30,404 - INFO - joeynmt.training - Epoch  10, Step:    36300, Batch Loss:     0.894608, Batch Acc: 0.601991, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 12:20:18,134 - INFO - joeynmt.training - Epoch  10, Step:    36400, Batch Loss:     1.120860, Batch Acc: 0.603302, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 12:21:06,824 - INFO - joeynmt.training - Epoch  10, Step:    36500, Batch Loss:     0.886685, Batch Acc: 0.597867, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 12:21:56,864 - INFO - joeynmt.training - Epoch  10, Step:    36600, Batch Loss:     1.098135, Batch Acc: 0.593036, Tokens per Sec:      335, Lr: 0.000200
2024-02-21 12:22:45,520 - INFO - joeynmt.training - Epoch  10, Step:    36700, Batch Loss:     1.024100, Batch Acc: 0.593242, Tokens per Sec:      349, Lr: 0.000200
2024-02-21 12:23:33,202 - INFO - joeynmt.training - Epoch  10, Step:    36800, Batch Loss:     1.170930, Batch Acc: 0.599204, Tokens per Sec:      369, Lr: 0.000200
2024-02-21 12:24:21,874 - INFO - joeynmt.training - Epoch  10, Step:    36900, Batch Loss:     1.001679, Batch Acc: 0.594925, Tokens per Sec:      364, Lr: 0.000200
2024-02-21 12:25:11,730 - INFO - joeynmt.training - Epoch  10, Step:    37000, Batch Loss:     0.795013, Batch Acc: 0.600288, Tokens per Sec:      348, Lr: 0.000200
2024-02-21 12:25:11,730 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.14it/s]
2024-02-21 12:26:00,910 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  47.60, loss:   1.40, ppl:   4.07, acc:   0.51, generation: 48.4891[sec], evaluation: 0.6677[sec]
2024-02-21 12:26:00,911 - INFO - joeynmt.training - Example #0
2024-02-21 12:26:00,912 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 12:26:00,912 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 12:26:00,912 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S26606501x503S26612471x503S2fb04492x561S20500495x501S20500495x501S1f450501x488S1ee58482x488S22104482x490S22104458x493S22104458x493
2024-02-21 12:26:00,912 - INFO - joeynmt.training - Example #1
2024-02-21 12:26:00,913 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 12:26:00,913 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 12:26:00,913 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S10002503x484S1000a469x484S2ea00508x503S2ea4c478x503S2fd04489x560
2024-02-21 12:26:00,913 - INFO - joeynmt.training - Example #2
2024-02-21 12:26:00,913 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 12:26:00,913 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 12:26:00,913 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x455S2ff00501x455S35d14453x475S1ce10531x493S2e500530x519S15a18500x502S15a11461x502S22a04461x502
2024-02-21 12:26:00,913 - INFO - joeynmt.training - Example #3
2024-02-21 12:26:00,914 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 12:26:00,914 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 12:26:00,914 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006469x472S35d10482x489S10011502x482S21100505x470S26a04505x503
2024-02-21 12:26:50,098 - INFO - joeynmt.training - Epoch  10, Step:    37100, Batch Loss:     0.956135, Batch Acc: 0.599063, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 12:27:37,551 - INFO - joeynmt.training - Epoch  10, Step:    37200, Batch Loss:     1.587062, Batch Acc: 0.598396, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 12:28:26,696 - INFO - joeynmt.training - Epoch  10, Step:    37300, Batch Loss:     1.040864, Batch Acc: 0.591265, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 12:29:16,326 - INFO - joeynmt.training - Epoch  10, Step:    37400, Batch Loss:     1.113743, Batch Acc: 0.598697, Tokens per Sec:      340, Lr: 0.000200
2024-02-21 12:30:04,755 - INFO - joeynmt.training - Epoch  10, Step:    37500, Batch Loss:     1.164096, Batch Acc: 0.592799, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 12:30:52,716 - INFO - joeynmt.training - Epoch  10, Step:    37600, Batch Loss:     0.798779, Batch Acc: 0.599633, Tokens per Sec:      341, Lr: 0.000200
2024-02-21 12:31:40,497 - INFO - joeynmt.training - Epoch  10, Step:    37700, Batch Loss:     1.308457, Batch Acc: 0.592844, Tokens per Sec:      364, Lr: 0.000200
2024-02-21 12:32:29,882 - INFO - joeynmt.training - Epoch  10, Step:    37800, Batch Loss:     1.003855, Batch Acc: 0.606569, Tokens per Sec:      339, Lr: 0.000200
2024-02-21 12:33:17,857 - INFO - joeynmt.training - Epoch  10, Step:    37900, Batch Loss:     1.095151, Batch Acc: 0.599942, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 12:34:04,964 - INFO - joeynmt.training - Epoch  10, Step:    38000, Batch Loss:     0.951123, Batch Acc: 0.591759, Tokens per Sec:      358, Lr: 0.000200
2024-02-21 12:34:04,964 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.09it/s]
2024-02-21 12:34:54,399 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  49.19, loss:   1.40, ppl:   4.07, acc:   0.51, generation: 48.7753[sec], evaluation: 0.6383[sec]
2024-02-21 12:34:54,400 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 12:34:54,905 - INFO - joeynmt.helpers - delete experiment/35000.ckpt
2024-02-21 12:34:54,944 - INFO - joeynmt.training - Example #0
2024-02-21 12:34:54,945 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 12:34:54,945 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 12:34:54,945 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S26606501x505S26612469x505S2fb04492x561S20500495x493S2fb04492x561S26606507x520S26612467x520
2024-02-21 12:34:54,945 - INFO - joeynmt.training - Example #1
2024-02-21 12:34:54,946 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 12:34:54,946 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 12:34:54,946 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S20500495x494S2fb04492x560S11002501x480S1100a475x480S22f02511x508S22f16471x508
2024-02-21 12:34:54,946 - INFO - joeynmt.training - Example #2
2024-02-21 12:34:54,946 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 12:34:54,947 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 12:34:54,947 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00436x450S2ff00509x450S35d14449x470S1ce10461x491S2e500447x522S15a10529x492S15a18495x492S22e02527x515S22e16506x515S2fb04521x544
2024-02-21 12:34:54,947 - INFO - joeynmt.training - Example #3
2024-02-21 12:34:54,948 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 12:34:54,948 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 12:34:54,948 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x474S35d14487x496S21100501x496S10010507x488S22a06507x507
2024-02-21 12:35:44,469 - INFO - joeynmt.training - Epoch  10, Step:    38100, Batch Loss:     0.962584, Batch Acc: 0.584950, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 12:36:32,943 - INFO - joeynmt.training - Epoch  10, Step:    38200, Batch Loss:     1.117650, Batch Acc: 0.588908, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 12:37:21,101 - INFO - joeynmt.training - Epoch  10, Step:    38300, Batch Loss:     1.089304, Batch Acc: 0.590583, Tokens per Sec:      342, Lr: 0.000200
2024-02-21 12:38:08,302 - INFO - joeynmt.training - Epoch  10, Step:    38400, Batch Loss:     1.269439, Batch Acc: 0.592824, Tokens per Sec:      366, Lr: 0.000200
2024-02-21 12:38:56,524 - INFO - joeynmt.training - Epoch  10, Step:    38500, Batch Loss:     0.989291, Batch Acc: 0.594649, Tokens per Sec:      349, Lr: 0.000200
2024-02-21 12:39:46,435 - INFO - joeynmt.training - Epoch  10, Step:    38600, Batch Loss:     1.071743, Batch Acc: 0.598477, Tokens per Sec:      342, Lr: 0.000200
2024-02-21 12:40:34,530 - INFO - joeynmt.training - Epoch  10, Step:    38700, Batch Loss:     0.983885, Batch Acc: 0.595540, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 12:41:21,599 - INFO - joeynmt.training - Epoch  10, Step:    38800, Batch Loss:     1.245924, Batch Acc: 0.596356, Tokens per Sec:      373, Lr: 0.000200
2024-02-21 12:42:09,934 - INFO - joeynmt.training - Epoch  10, Step:    38900, Batch Loss:     1.029434, Batch Acc: 0.601628, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 12:42:59,822 - INFO - joeynmt.training - Epoch  10, Step:    39000, Batch Loss:     1.333745, Batch Acc: 0.587515, Tokens per Sec:      344, Lr: 0.000200
2024-02-21 12:42:59,823 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:44<00:00,  7.80it/s]
2024-02-21 12:43:45,190 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  47.26, loss:   1.40, ppl:   4.07, acc:   0.52, generation: 44.3481[sec], evaluation: 0.9821[sec]
2024-02-21 12:43:45,192 - INFO - joeynmt.training - Example #0
2024-02-21 12:43:45,193 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 12:43:45,193 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 12:43:45,193 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S26606503x521S26612469x521S2fb04492x561S20500495x472S18250502x483S18258480x483
2024-02-21 12:43:45,193 - INFO - joeynmt.training - Example #1
2024-02-21 12:43:45,194 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 12:43:45,194 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 12:43:45,194 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d10495x455S20500495x477S2fb04492x560S10002502x490S1000a469x490S2ea00519x473S2ea4c471x513
2024-02-21 12:43:45,194 - INFO - joeynmt.training - Example #2
2024-02-21 12:43:45,195 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 12:43:45,196 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 12:43:45,196 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00509x443S30006443x443S35d10456x463S21100468x440S15310538x441S15318503x441S2fd04516x554S15310468x441S23000468x464S2df00464x481S2df10428x481
2024-02-21 12:43:45,196 - INFO - joeynmt.training - Example #3
2024-02-21 12:43:45,196 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 12:43:45,196 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 12:43:45,196 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x474S35d10487x493S10010498x488S21100502x474S26a04505x515
2024-02-21 12:44:32,965 - INFO - joeynmt.training - Epoch  10, Step:    39100, Batch Loss:     1.184209, Batch Acc: 0.601206, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 12:45:21,167 - INFO - joeynmt.training - Epoch  10, Step:    39200, Batch Loss:     1.014175, Batch Acc: 0.596049, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 12:46:09,451 - INFO - joeynmt.training - Epoch  10, Step:    39300, Batch Loss:     1.075065, Batch Acc: 0.591983, Tokens per Sec:      349, Lr: 0.000200
2024-02-21 12:46:53,260 - INFO - joeynmt.training - Epoch  10: total training loss 4219.65, num seqs 15756, num tokens 672796
2024-02-21 12:46:53,260 - INFO - joeynmt.training - EPOCH 11
2024-02-21 12:46:58,686 - INFO - joeynmt.training - Epoch  11, Step:    39400, Batch Loss:     0.762925, Batch Acc: 0.615211, Tokens per Sec:      327, Lr: 0.000200
2024-02-21 12:47:46,046 - INFO - joeynmt.training - Epoch  11, Step:    39500, Batch Loss:     0.987054, Batch Acc: 0.625686, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 12:48:34,542 - INFO - joeynmt.training - Epoch  11, Step:    39600, Batch Loss:     1.030790, Batch Acc: 0.627380, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 12:49:22,511 - INFO - joeynmt.training - Epoch  11, Step:    39700, Batch Loss:     1.065454, Batch Acc: 0.617195, Tokens per Sec:      342, Lr: 0.000200
2024-02-21 12:50:11,026 - INFO - joeynmt.training - Epoch  11, Step:    39800, Batch Loss:     0.804870, Batch Acc: 0.613893, Tokens per Sec:      340, Lr: 0.000200
2024-02-21 12:50:58,938 - INFO - joeynmt.training - Epoch  11, Step:    39900, Batch Loss:     1.212423, Batch Acc: 0.615154, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 12:51:47,215 - INFO - joeynmt.training - Epoch  11, Step:    40000, Batch Loss:     1.051618, Batch Acc: 0.621373, Tokens per Sec:      361, Lr: 0.000200
2024-02-21 12:51:47,216 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.10it/s]
2024-02-21 12:52:36,643 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  48.32, loss:   1.40, ppl:   4.07, acc:   0.51, generation: 48.7179[sec], evaluation: 0.6873[sec]
2024-02-21 12:52:36,644 - INFO - joeynmt.training - Example #0
2024-02-21 12:52:36,645 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 12:52:36,645 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 12:52:36,645 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S26606503x505S26612469x505S2fb04492x561S20350501x483S20350483x483S20500495x501
2024-02-21 12:52:36,645 - INFO - joeynmt.training - Example #1
2024-02-21 12:52:36,645 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 12:52:36,646 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 12:52:36,646 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S20500495x475S1ea0e501x493S1ea06477x493S2fb04492x561S22f02511x504S22f16477x504
2024-02-21 12:52:36,646 - INFO - joeynmt.training - Example #2
2024-02-21 12:52:36,646 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 12:52:36,646 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 12:52:36,646 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x434S2ff00513x434S35d10453x454S1ce10468x454S2e500452x491S2e500535x491S2e51c500x511S2fd04523x560S15310538x469S15318506x471
2024-02-21 12:52:36,646 - INFO - joeynmt.training - Example #3
2024-02-21 12:52:36,647 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 12:52:36,647 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 12:52:36,647 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006471x492S35d10484x507S10010506x481S21100506x481S22a06506x509
2024-02-21 12:53:25,564 - INFO - joeynmt.training - Epoch  11, Step:    40100, Batch Loss:     0.774930, Batch Acc: 0.620156, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 12:54:13,369 - INFO - joeynmt.training - Epoch  11, Step:    40200, Batch Loss:     1.259067, Batch Acc: 0.614766, Tokens per Sec:      364, Lr: 0.000200
2024-02-21 12:55:01,679 - INFO - joeynmt.training - Epoch  11, Step:    40300, Batch Loss:     1.028696, Batch Acc: 0.610771, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 12:55:49,745 - INFO - joeynmt.training - Epoch  11, Step:    40400, Batch Loss:     1.044666, Batch Acc: 0.614780, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 12:56:37,245 - INFO - joeynmt.training - Epoch  11, Step:    40500, Batch Loss:     1.321993, Batch Acc: 0.616793, Tokens per Sec:      374, Lr: 0.000200
2024-02-21 12:57:26,084 - INFO - joeynmt.training - Epoch  11, Step:    40600, Batch Loss:     1.125626, Batch Acc: 0.612999, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 12:58:13,949 - INFO - joeynmt.training - Epoch  11, Step:    40700, Batch Loss:     0.805980, Batch Acc: 0.616621, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 12:59:01,581 - INFO - joeynmt.training - Epoch  11, Step:    40800, Batch Loss:     1.213773, Batch Acc: 0.614852, Tokens per Sec:      358, Lr: 0.000200
2024-02-21 12:59:48,298 - INFO - joeynmt.training - Epoch  11, Step:    40900, Batch Loss:     1.030115, Batch Acc: 0.614108, Tokens per Sec:      370, Lr: 0.000200
2024-02-21 13:00:37,134 - INFO - joeynmt.training - Epoch  11, Step:    41000, Batch Loss:     1.217179, Batch Acc: 0.620949, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 13:00:37,134 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:46<00:00,  7.43it/s]
2024-02-21 13:01:24,373 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  49.08, loss:   1.43, ppl:   4.16, acc:   0.51, generation: 46.5836[sec], evaluation: 0.6333[sec]
2024-02-21 13:01:24,941 - INFO - joeynmt.helpers - delete experiment/33000.ckpt
2024-02-21 13:01:24,979 - INFO - joeynmt.training - Example #0
2024-02-21 13:01:24,980 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 13:01:24,980 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 13:01:24,980 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x437S36520495x459S26606503x482S26612469x482S2fb04493x558S20350501x482S20358483x482S20500495x508
2024-02-21 13:01:24,980 - INFO - joeynmt.training - Example #1
2024-02-21 13:01:24,981 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 13:01:24,981 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 13:01:24,981 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S1ea0e506x478S1ea06476x478S2fd04489x560S2ea00509x497S2ea4c476x507
2024-02-21 13:01:24,981 - INFO - joeynmt.training - Example #2
2024-02-21 13:01:24,981 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 13:01:24,981 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 13:01:24,981 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00439x437S2ff00512x437S35d14452x457S1ce10460x477S2e500437x510S18510536x480S18518499x480S2fd04519x558S14a20536x460S2e500536x499S2e518498x510
2024-02-21 13:01:24,981 - INFO - joeynmt.training - Example #3
2024-02-21 13:01:24,982 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 13:01:24,982 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 13:01:24,982 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006471x479S35d10484x501S10001502x488S20e00502x485S2ea06506x477
2024-02-21 13:02:13,106 - INFO - joeynmt.training - Epoch  11, Step:    41100, Batch Loss:     0.893242, Batch Acc: 0.610555, Tokens per Sec:      340, Lr: 0.000200
2024-02-21 13:02:59,456 - INFO - joeynmt.training - Epoch  11, Step:    41200, Batch Loss:     0.790645, Batch Acc: 0.613562, Tokens per Sec:      364, Lr: 0.000200
2024-02-21 13:03:47,995 - INFO - joeynmt.training - Epoch  11, Step:    41300, Batch Loss:     0.834584, Batch Acc: 0.614298, Tokens per Sec:      353, Lr: 0.000200
2024-02-21 13:04:37,364 - INFO - joeynmt.training - Epoch  11, Step:    41400, Batch Loss:     0.849498, Batch Acc: 0.610450, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 13:05:24,530 - INFO - joeynmt.training - Epoch  11, Step:    41500, Batch Loss:     0.997489, Batch Acc: 0.623598, Tokens per Sec:      365, Lr: 0.000200
2024-02-21 13:06:12,341 - INFO - joeynmt.training - Epoch  11, Step:    41600, Batch Loss:     0.990012, Batch Acc: 0.612871, Tokens per Sec:      361, Lr: 0.000200
2024-02-21 13:07:02,935 - INFO - joeynmt.training - Epoch  11, Step:    41700, Batch Loss:     0.963653, Batch Acc: 0.620368, Tokens per Sec:      339, Lr: 0.000200
2024-02-21 13:07:51,838 - INFO - joeynmt.training - Epoch  11, Step:    41800, Batch Loss:     0.844136, Batch Acc: 0.623779, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 13:08:39,647 - INFO - joeynmt.training - Epoch  11, Step:    41900, Batch Loss:     0.972607, Batch Acc: 0.617007, Tokens per Sec:      351, Lr: 0.000200
2024-02-21 13:09:26,522 - INFO - joeynmt.training - Epoch  11, Step:    42000, Batch Loss:     0.862139, Batch Acc: 0.612890, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 13:09:26,523 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:46<00:00,  7.47it/s]
2024-02-21 13:10:13,558 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  47.12, loss:   1.41, ppl:   4.09, acc:   0.51, generation: 46.3354[sec], evaluation: 0.6767[sec]
2024-02-21 13:10:13,559 - INFO - joeynmt.training - Example #0
2024-02-21 13:10:13,560 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 13:10:13,560 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 13:10:13,560 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S2fb04492x561S26606501x474S26612469x474S20500495x535S18250501x508S18258474x508
2024-02-21 13:10:13,560 - INFO - joeynmt.training - Example #1
2024-02-21 13:10:13,561 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 13:10:13,561 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 13:10:13,561 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d10495x455S11002503x476S1100a471x476S20500495x476S2fb04492x560S22f02511x508S22f16476x508
2024-02-21 13:10:13,561 - INFO - joeynmt.training - Example #2
2024-02-21 13:10:13,561 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 13:10:13,561 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 13:10:13,561 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x434S2ff00513x434S35d14453x454S1ce10463x471S2e500448x493S2fd04515x560S14a20525x472S2e500525x473S2e518499x502S2e508532x502
2024-02-21 13:10:13,561 - INFO - joeynmt.training - Example #3
2024-02-21 13:10:13,562 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 13:10:13,562 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 13:10:13,562 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x470S35d10487x490S10001500x500S26a04500x516
2024-02-21 13:11:03,107 - INFO - joeynmt.training - Epoch  11, Step:    42100, Batch Loss:     1.472897, Batch Acc: 0.624909, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 13:11:50,690 - INFO - joeynmt.training - Epoch  11, Step:    42200, Batch Loss:     1.015839, Batch Acc: 0.612469, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 13:12:38,302 - INFO - joeynmt.training - Epoch  11, Step:    42300, Batch Loss:     1.178027, Batch Acc: 0.612813, Tokens per Sec:      361, Lr: 0.000200
2024-02-21 13:13:26,222 - INFO - joeynmt.training - Epoch  11, Step:    42400, Batch Loss:     0.935047, Batch Acc: 0.606360, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 13:14:14,196 - INFO - joeynmt.training - Epoch  11, Step:    42500, Batch Loss:     0.896589, Batch Acc: 0.612861, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 13:15:03,280 - INFO - joeynmt.training - Epoch  11, Step:    42600, Batch Loss:     1.512994, Batch Acc: 0.604764, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 13:15:50,832 - INFO - joeynmt.training - Epoch  11, Step:    42700, Batch Loss:     0.745302, Batch Acc: 0.605055, Tokens per Sec:      374, Lr: 0.000200
2024-02-21 13:16:39,334 - INFO - joeynmt.training - Epoch  11, Step:    42800, Batch Loss:     1.064468, Batch Acc: 0.616296, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 13:17:27,433 - INFO - joeynmt.training - Epoch  11, Step:    42900, Batch Loss:     0.789389, Batch Acc: 0.618519, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 13:18:16,252 - INFO - joeynmt.training - Epoch  11, Step:    43000, Batch Loss:     0.873326, Batch Acc: 0.618649, Tokens per Sec:      355, Lr: 0.000200
2024-02-21 13:18:16,252 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:45<00:00,  7.54it/s]
2024-02-21 13:19:02,799 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  48.27, loss:   1.43, ppl:   4.17, acc:   0.51, generation: 45.8946[sec], evaluation: 0.6270[sec]
2024-02-21 13:19:02,801 - INFO - joeynmt.training - Example #0
2024-02-21 13:19:02,802 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 13:19:02,802 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 13:19:02,802 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00483x434S35d14496x454S2fb04493x561S26607507x475S26611472x475S22620502x472S22620476x506S22620476x506S22620476x491
2024-02-21 13:19:02,802 - INFO - joeynmt.training - Example #1
2024-02-21 13:19:02,803 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 13:19:02,803 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 13:19:02,803 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S1ea0e506x477S1ea06473x477S2fb04492x560S20500495x477S22f02517x511S22f16471x511
2024-02-21 13:19:02,803 - INFO - joeynmt.training - Example #2
2024-02-21 13:19:02,804 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 13:19:02,804 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 13:19:02,804 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x438S2ff00513x438S35d14453x458S2df00458x498S18510536x480S18518499x480S2fd04514x556S14a20458x480S2e500458x498
2024-02-21 13:19:02,804 - INFO - joeynmt.training - Example #3
2024-02-21 13:19:02,804 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 13:19:02,804 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 13:19:02,804 - INFO - joeynmt.training - 	Hypothesis: M500x500S30005470x468S35d14483x489S10011507x489S20500500x471S26a04505x503
2024-02-21 13:19:51,062 - INFO - joeynmt.training - Epoch  11, Step:    43100, Batch Loss:     1.123714, Batch Acc: 0.611003, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 13:20:38,962 - INFO - joeynmt.training - Epoch  11, Step:    43200, Batch Loss:     0.881644, Batch Acc: 0.613142, Tokens per Sec:      342, Lr: 0.000200
2024-02-21 13:21:25,987 - INFO - joeynmt.training - Epoch  11, Step:    43300, Batch Loss:     0.867388, Batch Acc: 0.611351, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 13:21:41,605 - INFO - joeynmt.training - Epoch  11: total training loss 4024.08, num seqs 15756, num tokens 672796
2024-02-21 13:21:41,605 - INFO - joeynmt.training - EPOCH 12
2024-02-21 13:22:14,906 - INFO - joeynmt.training - Epoch  12, Step:    43400, Batch Loss:     0.733718, Batch Acc: 0.648376, Tokens per Sec:      373, Lr: 0.000200
2024-02-21 13:23:03,096 - INFO - joeynmt.training - Epoch  12, Step:    43500, Batch Loss:     0.832825, Batch Acc: 0.636978, Tokens per Sec:      350, Lr: 0.000200
2024-02-21 13:23:50,935 - INFO - joeynmt.training - Epoch  12, Step:    43600, Batch Loss:     1.134894, Batch Acc: 0.638876, Tokens per Sec:      365, Lr: 0.000200
2024-02-21 13:24:38,209 - INFO - joeynmt.training - Epoch  12, Step:    43700, Batch Loss:     0.667387, Batch Acc: 0.650752, Tokens per Sec:      366, Lr: 0.000200
2024-02-21 13:25:26,833 - INFO - joeynmt.training - Epoch  12, Step:    43800, Batch Loss:     0.882350, Batch Acc: 0.638234, Tokens per Sec:      366, Lr: 0.000200
2024-02-21 13:26:14,334 - INFO - joeynmt.training - Epoch  12, Step:    43900, Batch Loss:     0.892585, Batch Acc: 0.636590, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 13:27:02,094 - INFO - joeynmt.training - Epoch  12, Step:    44000, Batch Loss:     1.278618, Batch Acc: 0.622620, Tokens per Sec:      371, Lr: 0.000200
2024-02-21 13:27:02,095 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:50<00:00,  6.81it/s]
2024-02-21 13:27:53,593 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  49.74, loss:   1.44, ppl:   4.20, acc:   0.52, generation: 50.7839[sec], evaluation: 0.6911[sec]
2024-02-21 13:27:53,593 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 13:27:54,173 - INFO - joeynmt.helpers - delete experiment/41000.ckpt
2024-02-21 13:27:54,215 - INFO - joeynmt.training - Example #0
2024-02-21 13:27:54,216 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 13:27:54,216 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 13:27:54,216 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x441S35010494x464S20500495x489S2fb04493x554S26606507x513S26612469x513S22200505x488S22200485x488S22200484x488S22200484x488S22200501x488S22200484x488S22200501x489S2fb04493x554
2024-02-21 13:27:54,216 - INFO - joeynmt.training - Example #1
2024-02-21 13:27:54,217 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 13:27:54,217 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 13:27:54,217 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x560S20500495x493S11002501x476S1100a472x476S22f02515x511S22f16471x511
2024-02-21 13:27:54,217 - INFO - joeynmt.training - Example #2
2024-02-21 13:27:54,218 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 13:27:54,218 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 13:27:54,218 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00448x434S2ff00509x434S35d10461x454S1ce10468x472S2e500454x496S14c10528x472S14c18498x473S2fb04516x560S22204534x472S22204534x473S22204520x472S22204520x472
2024-02-21 13:27:54,218 - INFO - joeynmt.training - Example #3
2024-02-21 13:27:54,218 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 13:27:54,218 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 13:27:54,218 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x472S35d10487x493S10000500x474S20500501x474S26a04501x515
2024-02-21 13:28:42,735 - INFO - joeynmt.training - Epoch  12, Step:    44100, Batch Loss:     1.039066, Batch Acc: 0.641997, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 13:29:30,981 - INFO - joeynmt.training - Epoch  12, Step:    44200, Batch Loss:     1.177542, Batch Acc: 0.632481, Tokens per Sec:      348, Lr: 0.000200
2024-02-21 13:30:18,751 - INFO - joeynmt.training - Epoch  12, Step:    44300, Batch Loss:     0.908837, Batch Acc: 0.642642, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 13:31:06,830 - INFO - joeynmt.training - Epoch  12, Step:    44400, Batch Loss:     1.013185, Batch Acc: 0.638011, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 13:31:54,181 - INFO - joeynmt.training - Epoch  12, Step:    44500, Batch Loss:     0.769793, Batch Acc: 0.630139, Tokens per Sec:      366, Lr: 0.000200
2024-02-21 13:32:42,975 - INFO - joeynmt.training - Epoch  12, Step:    44600, Batch Loss:     0.626468, Batch Acc: 0.630744, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 13:33:30,774 - INFO - joeynmt.training - Epoch  12, Step:    44700, Batch Loss:     0.905423, Batch Acc: 0.639043, Tokens per Sec:      366, Lr: 0.000200
2024-02-21 13:34:18,457 - INFO - joeynmt.training - Epoch  12, Step:    44800, Batch Loss:     0.756553, Batch Acc: 0.634248, Tokens per Sec:      367, Lr: 0.000200
2024-02-21 13:35:04,910 - INFO - joeynmt.training - Epoch  12, Step:    44900, Batch Loss:     1.060819, Batch Acc: 0.631091, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 13:35:52,589 - INFO - joeynmt.training - Epoch  12, Step:    45000, Batch Loss:     1.258712, Batch Acc: 0.635883, Tokens per Sec:      341, Lr: 0.000200
2024-02-21 13:35:52,589 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:50<00:00,  6.91it/s]
2024-02-21 13:36:43,312 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  47.59, loss:   1.44, ppl:   4.23, acc:   0.51, generation: 50.0421[sec], evaluation: 0.6563[sec]
2024-02-21 13:36:43,314 - INFO - joeynmt.training - Example #0
2024-02-21 13:36:43,314 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 13:36:43,315 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 13:36:43,315 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S26606503x505S26612468x505S10050501x482S10058480x482S2fb04493x560
2024-02-21 13:36:43,315 - INFO - joeynmt.training - Example #1
2024-02-21 13:36:43,315 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 13:36:43,315 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 13:36:43,315 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S1ea0e506x478S1ea06473x482S20500495x476S2fb04493x560S22f02509x515S22f16476x515
2024-02-21 13:36:43,315 - INFO - joeynmt.training - Example #2
2024-02-21 13:36:43,316 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 13:36:43,316 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 13:36:43,316 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x440S2ff00513x440S35d10453x460S1ce10468x469S2e500458x504S2fd04523x554S15010540x479S26500540x479S26510504x505S26500510x510S26500540x510S26510498x510S26500498x510S26510499x510
2024-02-21 13:36:43,316 - INFO - joeynmt.training - Example #3
2024-02-21 13:36:43,317 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 13:36:43,317 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 13:36:43,317 - INFO - joeynmt.training - 	Hypothesis: M500x500S30005466x476S35d10479x496S10001502x488S21100502x485S22a04507x507
2024-02-21 13:37:31,421 - INFO - joeynmt.training - Epoch  12, Step:    45100, Batch Loss:     1.063024, Batch Acc: 0.635039, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 13:38:19,490 - INFO - joeynmt.training - Epoch  12, Step:    45200, Batch Loss:     0.829268, Batch Acc: 0.624505, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 13:39:06,344 - INFO - joeynmt.training - Epoch  12, Step:    45300, Batch Loss:     0.789149, Batch Acc: 0.639125, Tokens per Sec:      366, Lr: 0.000200
2024-02-21 13:39:55,080 - INFO - joeynmt.training - Epoch  12, Step:    45400, Batch Loss:     0.858946, Batch Acc: 0.632227, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 13:40:42,514 - INFO - joeynmt.training - Epoch  12, Step:    45500, Batch Loss:     1.468858, Batch Acc: 0.630122, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 13:41:29,972 - INFO - joeynmt.training - Epoch  12, Step:    45600, Batch Loss:     1.037831, Batch Acc: 0.634579, Tokens per Sec:      366, Lr: 0.000200
2024-02-21 13:42:16,770 - INFO - joeynmt.training - Epoch  12, Step:    45700, Batch Loss:     1.007139, Batch Acc: 0.635879, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 13:43:04,702 - INFO - joeynmt.training - Epoch  12, Step:    45800, Batch Loss:     0.899185, Batch Acc: 0.631197, Tokens per Sec:      356, Lr: 0.000200
2024-02-21 13:43:53,814 - INFO - joeynmt.training - Epoch  12, Step:    45900, Batch Loss:     1.338763, Batch Acc: 0.628142, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 13:44:40,498 - INFO - joeynmt.training - Epoch  12, Step:    46000, Batch Loss:     1.082250, Batch Acc: 0.631889, Tokens per Sec:      371, Lr: 0.000200
2024-02-21 13:44:40,498 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:50<00:00,  6.83it/s]
2024-02-21 13:45:31,887 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  49.65, loss:   1.44, ppl:   4.21, acc:   0.52, generation: 50.6819[sec], evaluation: 0.6830[sec]
2024-02-21 13:45:32,706 - INFO - joeynmt.helpers - delete experiment/38000.ckpt
2024-02-21 13:45:32,772 - INFO - joeynmt.training - Example #0
2024-02-21 13:45:32,774 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 13:45:32,774 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 13:45:32,774 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x561S26606503x498S26612469x498S20500495x472S18250501x483S18258483x483
2024-02-21 13:45:32,774 - INFO - joeynmt.training - Example #1
2024-02-21 13:45:32,775 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 13:45:32,775 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 13:45:32,775 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x560S20500495x493S1ea0e506x493S1ea06473x493S22f02511x517S22f16471x517
2024-02-21 13:45:32,775 - INFO - joeynmt.training - Example #2
2024-02-21 13:45:32,775 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 13:45:32,776 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 13:45:32,776 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00437x440S2ff00510x440S35d14450x460S1ce10460x467S2e500449x493S2fd04515x555S18210525x485S18218500x485S22a00552x514S22a10508x514
2024-02-21 13:45:32,776 - INFO - joeynmt.training - Example #3
2024-02-21 13:45:32,776 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 13:45:32,776 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 13:45:32,776 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x472S35d14487x493S10001511x487S20500507x472S22a03507x507
2024-02-21 13:46:20,829 - INFO - joeynmt.training - Epoch  12, Step:    46100, Batch Loss:     0.981913, Batch Acc: 0.630548, Tokens per Sec:      341, Lr: 0.000200
2024-02-21 13:47:10,323 - INFO - joeynmt.training - Epoch  12, Step:    46200, Batch Loss:     1.199478, Batch Acc: 0.623254, Tokens per Sec:      337, Lr: 0.000200
2024-02-21 13:47:58,322 - INFO - joeynmt.training - Epoch  12, Step:    46300, Batch Loss:     0.968339, Batch Acc: 0.629300, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 13:48:45,669 - INFO - joeynmt.training - Epoch  12, Step:    46400, Batch Loss:     0.904036, Batch Acc: 0.632144, Tokens per Sec:      374, Lr: 0.000200
2024-02-21 13:49:33,973 - INFO - joeynmt.training - Epoch  12, Step:    46500, Batch Loss:     1.042636, Batch Acc: 0.627256, Tokens per Sec:      353, Lr: 0.000200
2024-02-21 13:50:22,659 - INFO - joeynmt.training - Epoch  12, Step:    46600, Batch Loss:     1.125471, Batch Acc: 0.633945, Tokens per Sec:      345, Lr: 0.000200
2024-02-21 13:51:12,367 - INFO - joeynmt.training - Epoch  12, Step:    46700, Batch Loss:     0.909748, Batch Acc: 0.625362, Tokens per Sec:      355, Lr: 0.000200
2024-02-21 13:52:00,524 - INFO - joeynmt.training - Epoch  12, Step:    46800, Batch Loss:     1.257483, Batch Acc: 0.631377, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 13:52:47,401 - INFO - joeynmt.training - Epoch  12, Step:    46900, Batch Loss:     0.675924, Batch Acc: 0.629611, Tokens per Sec:      374, Lr: 0.000200
2024-02-21 13:53:35,122 - INFO - joeynmt.training - Epoch  12, Step:    47000, Batch Loss:     0.955066, Batch Acc: 0.629627, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 13:53:35,122 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:51<00:00,  6.76it/s]
2024-02-21 13:54:27,029 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  47.76, loss:   1.44, ppl:   4.22, acc:   0.52, generation: 51.1883[sec], evaluation: 0.6956[sec]
2024-02-21 13:54:27,031 - INFO - joeynmt.training - Example #0
2024-02-21 13:54:27,031 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 13:54:27,031 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 13:54:27,032 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S2fb04493x561S26606501x482S26612469x482S20500495x472S22620476x491S22620504x491S22620476x491S22620476x491
2024-02-21 13:54:27,032 - INFO - joeynmt.training - Example #1
2024-02-21 13:54:27,032 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 13:54:27,032 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 13:54:27,032 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S1000a472x492S10002509x492S1000a469x492S2fd04489x560S2ea00509x509S2ea4c478x508
2024-02-21 13:54:27,033 - INFO - joeynmt.training - Example #2
2024-02-21 13:54:27,033 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 13:54:27,033 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 13:54:27,033 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00446x436S2ff00507x436S35d14459x456S1ce10532x478S1ce18501x478S2fd04516x559S2841e501x509S28436548x510S28436548x510
2024-02-21 13:54:27,033 - INFO - joeynmt.training - Example #3
2024-02-21 13:54:27,034 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 13:54:27,034 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 13:54:27,034 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006446x471S30006500x471S35d10459x491S21100473x462S10020473x472S21100473x462S10020534x491S24e3c534x505
2024-02-21 13:55:16,613 - INFO - joeynmt.training - Epoch  12, Step:    47100, Batch Loss:     1.321069, Batch Acc: 0.628961, Tokens per Sec:      333, Lr: 0.000200
2024-02-21 13:56:04,009 - INFO - joeynmt.training - Epoch  12, Step:    47200, Batch Loss:     0.916761, Batch Acc: 0.629819, Tokens per Sec:      355, Lr: 0.000200
2024-02-21 13:56:36,554 - INFO - joeynmt.training - Epoch  12: total training loss 3843.76, num seqs 15756, num tokens 672796
2024-02-21 13:56:36,555 - INFO - joeynmt.training - EPOCH 13
2024-02-21 13:56:51,878 - INFO - joeynmt.training - Epoch  13, Step:    47300, Batch Loss:     0.893469, Batch Acc: 0.657083, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 13:57:40,049 - INFO - joeynmt.training - Epoch  13, Step:    47400, Batch Loss:     1.060573, Batch Acc: 0.663362, Tokens per Sec:      337, Lr: 0.000200
2024-02-21 13:58:29,503 - INFO - joeynmt.training - Epoch  13, Step:    47500, Batch Loss:     0.817089, Batch Acc: 0.654997, Tokens per Sec:      338, Lr: 0.000200
2024-02-21 13:59:17,006 - INFO - joeynmt.training - Epoch  13, Step:    47600, Batch Loss:     0.814050, Batch Acc: 0.654920, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 14:00:04,360 - INFO - joeynmt.training - Epoch  13, Step:    47700, Batch Loss:     0.918517, Batch Acc: 0.667397, Tokens per Sec:      337, Lr: 0.000200
2024-02-21 14:00:52,093 - INFO - joeynmt.training - Epoch  13, Step:    47800, Batch Loss:     0.820581, Batch Acc: 0.665282, Tokens per Sec:      343, Lr: 0.000200
2024-02-21 14:01:39,716 - INFO - joeynmt.training - Epoch  13, Step:    47900, Batch Loss:     0.772675, Batch Acc: 0.654800, Tokens per Sec:      366, Lr: 0.000200
2024-02-21 14:02:27,034 - INFO - joeynmt.training - Epoch  13, Step:    48000, Batch Loss:     1.064811, Batch Acc: 0.655712, Tokens per Sec:      367, Lr: 0.000200
2024-02-21 14:02:27,035 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:46<00:00,  7.47it/s]
2024-02-21 14:03:13,990 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  48.20, loss:   1.47, ppl:   4.33, acc:   0.52, generation: 46.3247[sec], evaluation: 0.6093[sec]
2024-02-21 14:03:13,992 - INFO - joeynmt.training - Example #0
2024-02-21 14:03:13,992 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 14:03:13,992 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 14:03:13,993 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S26606503x509S26612468x509S2fb04492x561S22200505x482S22200483x470S22200483x470S22200505x470S22200484x470
2024-02-21 14:03:13,993 - INFO - joeynmt.training - Example #1
2024-02-21 14:03:13,993 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 14:03:13,993 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 14:03:13,993 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x560S20342501x476S2034a483x477S2360c504x503S23618475x503
2024-02-21 14:03:13,993 - INFO - joeynmt.training - Example #2
2024-02-21 14:03:13,994 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 14:03:13,994 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 14:03:13,994 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x434S2ff00501x434S35d14453x454S1ce10532x471S2e500529x501S24e38501x520S24e48501x520S2fd04515x560S1ce10451x472S1ce18432x471
2024-02-21 14:03:13,994 - INFO - joeynmt.training - Example #3
2024-02-21 14:03:13,994 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 14:03:13,995 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 14:03:13,995 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00471x479S36110478x501S10001488x491S2e500506x506
2024-02-21 14:04:01,940 - INFO - joeynmt.training - Epoch  13, Step:    48100, Batch Loss:     0.632999, Batch Acc: 0.657202, Tokens per Sec:      364, Lr: 0.000200
2024-02-21 14:04:48,915 - INFO - joeynmt.training - Epoch  13, Step:    48200, Batch Loss:     0.724959, Batch Acc: 0.661606, Tokens per Sec:      363, Lr: 0.000200
2024-02-21 14:05:36,440 - INFO - joeynmt.training - Epoch  13, Step:    48300, Batch Loss:     0.960670, Batch Acc: 0.649546, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 14:06:25,150 - INFO - joeynmt.training - Epoch  13, Step:    48400, Batch Loss:     0.805498, Batch Acc: 0.652400, Tokens per Sec:      347, Lr: 0.000200
2024-02-21 14:07:13,177 - INFO - joeynmt.training - Epoch  13, Step:    48500, Batch Loss:     0.623742, Batch Acc: 0.652500, Tokens per Sec:      377, Lr: 0.000200
2024-02-21 14:07:59,843 - INFO - joeynmt.training - Epoch  13, Step:    48600, Batch Loss:     0.830437, Batch Acc: 0.658350, Tokens per Sec:      370, Lr: 0.000200
2024-02-21 14:08:47,561 - INFO - joeynmt.training - Epoch  13, Step:    48700, Batch Loss:     0.806327, Batch Acc: 0.649255, Tokens per Sec:      365, Lr: 0.000200
2024-02-21 14:09:36,542 - INFO - joeynmt.training - Epoch  13, Step:    48800, Batch Loss:     0.965193, Batch Acc: 0.648867, Tokens per Sec:      346, Lr: 0.000200
2024-02-21 14:10:23,668 - INFO - joeynmt.training - Epoch  13, Step:    48900, Batch Loss:     0.765219, Batch Acc: 0.652159, Tokens per Sec:      373, Lr: 0.000200
2024-02-21 14:11:10,329 - INFO - joeynmt.training - Epoch  13, Step:    49000, Batch Loss:     0.882687, Batch Acc: 0.645927, Tokens per Sec:      365, Lr: 0.000200
2024-02-21 14:11:10,329 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:45<00:00,  7.55it/s]
2024-02-21 14:11:56,754 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  48.35, loss:   1.46, ppl:   4.31, acc:   0.52, generation: 45.8012[sec], evaluation: 0.6017[sec]
2024-02-21 14:11:56,756 - INFO - joeynmt.training - Example #0
2024-02-21 14:11:56,756 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 14:11:56,756 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 14:11:56,756 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x561S26606501x498S26612469x498S20500495x472S22200489x471S22200489x471S22200489x471S20350501x502S20350483x502
2024-02-21 14:11:56,757 - INFO - joeynmt.training - Example #1
2024-02-21 14:11:56,757 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 14:11:56,757 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 14:11:56,757 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S36520495x457S1ea41501x480S1ea49476x480S20500495x479S2fb04493x560S22f02520x499S22f16471x499
2024-02-21 14:11:56,757 - INFO - joeynmt.training - Example #2
2024-02-21 14:11:56,758 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 14:11:56,758 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 14:11:56,758 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x434S2ff00503x434S36110451x455S15020460x473S26500460x473S24e00468x473S24e48498x473S2fd04520x560S1ce10525x473S1ce10532x473S20a00525x503
2024-02-21 14:11:56,758 - INFO - joeynmt.training - Example #3
2024-02-21 14:11:56,759 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 14:11:56,759 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 14:11:56,759 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006469x472S35d10482x493S10011498x488S21100500x472S22114501x493
2024-02-21 14:12:44,503 - INFO - joeynmt.training - Epoch  13, Step:    49100, Batch Loss:     0.965959, Batch Acc: 0.643936, Tokens per Sec:      352, Lr: 0.000200
2024-02-21 14:13:32,759 - INFO - joeynmt.training - Epoch  13, Step:    49200, Batch Loss:     1.204236, Batch Acc: 0.651380, Tokens per Sec:      368, Lr: 0.000200
2024-02-21 14:14:20,699 - INFO - joeynmt.training - Epoch  13, Step:    49300, Batch Loss:     1.110938, Batch Acc: 0.643809, Tokens per Sec:      354, Lr: 0.000200
2024-02-21 14:15:08,713 - INFO - joeynmt.training - Epoch  13, Step:    49400, Batch Loss:     1.418313, Batch Acc: 0.644976, Tokens per Sec:      362, Lr: 0.000200
2024-02-21 14:15:56,702 - INFO - joeynmt.training - Epoch  13, Step:    49500, Batch Loss:     0.911226, Batch Acc: 0.648258, Tokens per Sec:      359, Lr: 0.000200
2024-02-21 14:16:43,686 - INFO - joeynmt.training - Epoch  13, Step:    49600, Batch Loss:     0.734566, Batch Acc: 0.651552, Tokens per Sec:      370, Lr: 0.000200
2024-02-21 14:17:32,589 - INFO - joeynmt.training - Epoch  13, Step:    49700, Batch Loss:     0.675102, Batch Acc: 0.650338, Tokens per Sec:      351, Lr: 0.000200
2024-02-21 14:18:20,280 - INFO - joeynmt.training - Epoch  13, Step:    49800, Batch Loss:     1.088606, Batch Acc: 0.654646, Tokens per Sec:      357, Lr: 0.000200
2024-02-21 14:19:07,969 - INFO - joeynmt.training - Epoch  13, Step:    49900, Batch Loss:     0.861777, Batch Acc: 0.643060, Tokens per Sec:      361, Lr: 0.000200
2024-02-21 14:19:55,085 - INFO - joeynmt.training - Epoch  13, Step:    50000, Batch Loss:     0.891281, Batch Acc: 0.656444, Tokens per Sec:      360, Lr: 0.000200
2024-02-21 14:19:55,086 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:44<00:00,  7.75it/s]
2024-02-21 14:20:40,396 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  47.71, loss:   1.47, ppl:   4.34, acc:   0.52, generation: 44.6727[sec], evaluation: 0.6157[sec]
2024-02-21 14:20:40,398 - INFO - joeynmt.training - Example #0
2024-02-21 14:20:40,398 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 14:20:40,398 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 14:20:40,399 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x441S35d10495x461S26606503x513S26612468x513S2fb04492x554S20500495x482S18250501x495S18258476x495
2024-02-21 14:20:40,399 - INFO - joeynmt.training - Example #1
2024-02-21 14:20:40,399 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 14:20:40,399 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 14:20:40,399 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S20342503x478S2034a482x478S22a02505x505S22a16483x505S2fb04492x560
2024-02-21 14:20:40,399 - INFO - joeynmt.training - Example #2
2024-02-21 14:20:40,400 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 14:20:40,400 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 14:20:40,400 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00432x440S2ff00505x440S35d10445x460S1ce10460x467S2e500453x507S14c10530x480S14c18500x480S2fd04513x555S22520537x473S22520507x473S22520530x478
2024-02-21 14:20:40,400 - INFO - joeynmt.training - Example #3
2024-02-21 14:20:40,400 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 14:20:40,401 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 14:20:40,401 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x471S35d10487x491S10000511x489S20500511x489S26a04501x515
2024-02-21 14:21:29,191 - INFO - joeynmt.training - Epoch  13, Step:    50100, Batch Loss:     0.738112, Batch Acc: 0.651153, Tokens per Sec:      342, Lr: 0.000020
2024-02-21 14:22:16,332 - INFO - joeynmt.training - Epoch  13, Step:    50200, Batch Loss:     0.775970, Batch Acc: 0.656121, Tokens per Sec:      371, Lr: 0.000020
2024-02-21 14:23:04,388 - INFO - joeynmt.training - Epoch  13, Step:    50300, Batch Loss:     0.949054, Batch Acc: 0.659749, Tokens per Sec:      340, Lr: 0.000020
2024-02-21 14:23:52,416 - INFO - joeynmt.training - Epoch  13, Step:    50400, Batch Loss:     0.703307, Batch Acc: 0.668843, Tokens per Sec:      354, Lr: 0.000020
2024-02-21 14:24:39,574 - INFO - joeynmt.training - Epoch  13, Step:    50500, Batch Loss:     0.717214, Batch Acc: 0.659415, Tokens per Sec:      363, Lr: 0.000020
2024-02-21 14:25:28,114 - INFO - joeynmt.training - Epoch  13, Step:    50600, Batch Loss:     0.732815, Batch Acc: 0.672439, Tokens per Sec:      346, Lr: 0.000020
2024-02-21 14:26:16,273 - INFO - joeynmt.training - Epoch  13, Step:    50700, Batch Loss:     0.747144, Batch Acc: 0.657953, Tokens per Sec:      366, Lr: 0.000020
2024-02-21 14:27:04,247 - INFO - joeynmt.training - Epoch  13, Step:    50800, Batch Loss:     1.013893, Batch Acc: 0.664114, Tokens per Sec:      365, Lr: 0.000020
2024-02-21 14:27:51,697 - INFO - joeynmt.training - Epoch  13, Step:    50900, Batch Loss:     0.778572, Batch Acc: 0.664068, Tokens per Sec:      360, Lr: 0.000020
2024-02-21 14:28:41,069 - INFO - joeynmt.training - Epoch  13, Step:    51000, Batch Loss:     1.052924, Batch Acc: 0.675963, Tokens per Sec:      339, Lr: 0.000020
2024-02-21 14:28:41,069 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.19it/s]
2024-02-21 14:29:29,872 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  51.23, loss:   1.43, ppl:   4.20, acc:   0.53, generation: 48.1356[sec], evaluation: 0.6330[sec]
2024-02-21 14:29:29,872 - INFO - __main__ - Hooray! New best validation result [fsw_eval]!
2024-02-21 14:29:32,002 - INFO - joeynmt.helpers - delete experiment/46000.ckpt
2024-02-21 14:29:32,044 - INFO - joeynmt.training - Example #0
2024-02-21 14:29:32,050 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 14:29:32,052 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 14:29:32,054 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x561S26606503x520S26612469x520S20500495x503S18250501x483S18258481x483
2024-02-21 14:29:32,056 - INFO - joeynmt.training - Example #1
2024-02-21 14:29:32,062 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 14:29:32,064 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 14:29:32,066 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S10002507x495S1000a469x496S2ea00508x493S2ea4c478x513S2fd04489x560
2024-02-21 14:29:32,068 - INFO - joeynmt.training - Example #2
2024-02-21 14:29:32,076 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 14:29:32,078 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 14:29:32,080 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00436x450S2ff00509x450S35d14449x470S1ce10468x471S2e500447x504S1ce10527x487S1ce48501x487S2fd04516x544S23104529x492S2311c498x515
2024-02-21 14:29:32,082 - INFO - joeynmt.training - Example #3
2024-02-21 14:29:32,088 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 14:29:32,090 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 14:29:32,092 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x472S35d10487x492S10000507x475S21100501x475S26a04501x509
2024-02-21 14:30:20,743 - INFO - joeynmt.training - Epoch  13, Step:    51100, Batch Loss:     1.089703, Batch Acc: 0.664409, Tokens per Sec:      331, Lr: 0.000020
2024-02-21 14:31:09,004 - INFO - joeynmt.training - Epoch  13, Step:    51200, Batch Loss:     0.716793, Batch Acc: 0.665953, Tokens per Sec:      368, Lr: 0.000020
2024-02-21 14:31:12,078 - INFO - joeynmt.training - Epoch  13: total training loss 3610.34, num seqs 15756, num tokens 672796
2024-02-21 14:31:12,078 - INFO - joeynmt.training - EPOCH 14
2024-02-21 14:31:56,516 - INFO - joeynmt.training - Epoch  14, Step:    51300, Batch Loss:     0.917467, Batch Acc: 0.703265, Tokens per Sec:      354, Lr: 0.000020
2024-02-21 14:32:45,527 - INFO - joeynmt.training - Epoch  14, Step:    51400, Batch Loss:     0.931280, Batch Acc: 0.705695, Tokens per Sec:      345, Lr: 0.000020
2024-02-21 14:33:33,382 - INFO - joeynmt.training - Epoch  14, Step:    51500, Batch Loss:     1.031867, Batch Acc: 0.701428, Tokens per Sec:      351, Lr: 0.000020
2024-02-21 14:34:21,961 - INFO - joeynmt.training - Epoch  14, Step:    51600, Batch Loss:     0.727544, Batch Acc: 0.701064, Tokens per Sec:      356, Lr: 0.000020
2024-02-21 14:35:10,263 - INFO - joeynmt.training - Epoch  14, Step:    51700, Batch Loss:     0.564409, Batch Acc: 0.707404, Tokens per Sec:      367, Lr: 0.000020
2024-02-21 14:35:57,881 - INFO - joeynmt.training - Epoch  14, Step:    51800, Batch Loss:     0.937940, Batch Acc: 0.709610, Tokens per Sec:      361, Lr: 0.000020
2024-02-21 14:36:47,820 - INFO - joeynmt.training - Epoch  14, Step:    51900, Batch Loss:     0.877965, Batch Acc: 0.698037, Tokens per Sec:      342, Lr: 0.000020
2024-02-21 14:37:36,102 - INFO - joeynmt.training - Epoch  14, Step:    52000, Batch Loss:     0.705857, Batch Acc: 0.701936, Tokens per Sec:      342, Lr: 0.000020
2024-02-21 14:37:36,102 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.14it/s]
2024-02-21 14:38:25,667 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  50.09, loss:   1.44, ppl:   4.24, acc:   0.53, generation: 48.4390[sec], evaluation: 1.0807[sec]
2024-02-21 14:38:29,849 - INFO - joeynmt.helpers - delete experiment/44000.ckpt
2024-02-21 14:38:29,892 - INFO - joeynmt.training - Example #0
2024-02-21 14:38:29,898 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 14:38:29,900 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 14:38:29,902 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x561S26606503x498S26612469x498S20500495x472S22200483x470S22200503x471S20350501x483S20350484x483
2024-02-21 14:38:29,904 - INFO - joeynmt.training - Example #1
2024-02-21 14:38:29,911 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 14:38:29,913 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 14:38:29,916 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x560S20500495x493S1ea0e506x479S1ea06470x479S22f02509x511S22f16477x511
2024-02-21 14:38:29,918 - INFO - joeynmt.training - Example #2
2024-02-21 14:38:29,927 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 14:38:29,929 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 14:38:29,931 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00436x450S2ff00509x450S35d14449x470S1ce10468x471S2e500447x504S1ce10527x487S1ce18498x487S2fd04516x544S23104529x492S2311c498x515
2024-02-21 14:38:29,933 - INFO - joeynmt.training - Example #3
2024-02-21 14:38:29,939 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 14:38:29,941 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 14:38:29,943 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x472S35d10487x492S10011498x501S21100501x482S22a04507x516
2024-02-21 14:39:18,826 - INFO - joeynmt.training - Epoch  14, Step:    52100, Batch Loss:     0.720729, Batch Acc: 0.709873, Tokens per Sec:      331, Lr: 0.000020
2024-02-21 14:40:07,103 - INFO - joeynmt.training - Epoch  14, Step:    52200, Batch Loss:     0.588883, Batch Acc: 0.706145, Tokens per Sec:      357, Lr: 0.000020
2024-02-21 14:40:56,326 - INFO - joeynmt.training - Epoch  14, Step:    52300, Batch Loss:     0.692997, Batch Acc: 0.705707, Tokens per Sec:      340, Lr: 0.000020
2024-02-21 14:41:44,628 - INFO - joeynmt.training - Epoch  14, Step:    52400, Batch Loss:     0.929062, Batch Acc: 0.703734, Tokens per Sec:      359, Lr: 0.000020
2024-02-21 14:42:32,915 - INFO - joeynmt.training - Epoch  14, Step:    52500, Batch Loss:     0.859545, Batch Acc: 0.713485, Tokens per Sec:      355, Lr: 0.000020
2024-02-21 14:43:21,488 - INFO - joeynmt.training - Epoch  14, Step:    52600, Batch Loss:     0.907514, Batch Acc: 0.700547, Tokens per Sec:      358, Lr: 0.000020
2024-02-21 14:44:08,686 - INFO - joeynmt.training - Epoch  14, Step:    52700, Batch Loss:     0.556827, Batch Acc: 0.704414, Tokens per Sec:      360, Lr: 0.000020
2024-02-21 14:44:58,439 - INFO - joeynmt.training - Epoch  14, Step:    52800, Batch Loss:     0.946791, Batch Acc: 0.704923, Tokens per Sec:      346, Lr: 0.000020
2024-02-21 14:45:46,884 - INFO - joeynmt.training - Epoch  14, Step:    52900, Batch Loss:     0.704557, Batch Acc: 0.704961, Tokens per Sec:      360, Lr: 0.000020
2024-02-21 14:46:35,087 - INFO - joeynmt.training - Epoch  14, Step:    53000, Batch Loss:     0.522817, Batch Acc: 0.700639, Tokens per Sec:      354, Lr: 0.000020
2024-02-21 14:46:35,087 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.14it/s]
2024-02-21 14:47:24,687 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  51.11, loss:   1.45, ppl:   4.26, acc:   0.53, generation: 48.4511[sec], evaluation: 1.1045[sec]
2024-02-21 14:47:25,541 - INFO - joeynmt.helpers - delete experiment/52000.ckpt
2024-02-21 14:47:25,605 - INFO - joeynmt.helpers - delete /content/signwriting-transcription/experiment/52000.ckpt
2024-02-21 14:47:25,605 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/signwriting-transcription/experiment/52000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/signwriting-transcription/experiment/52000.ckpt')
2024-02-21 14:47:25,606 - INFO - joeynmt.training - Example #0
2024-02-21 14:47:25,608 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 14:47:25,608 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 14:47:25,608 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S2fb04492x561S26606503x520S26612469x520S20500495x503S18250501x483S18258479x483
2024-02-21 14:47:25,608 - INFO - joeynmt.training - Example #1
2024-02-21 14:47:25,609 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 14:47:25,609 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 14:47:25,609 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S10002507x476S1000a469x476S2ea00508x502S2ea4c478x502S2fd04489x560
2024-02-21 14:47:25,609 - INFO - joeynmt.training - Example #2
2024-02-21 14:47:25,610 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 14:47:25,610 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 14:47:25,610 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00432x440S2ff00505x440S35d10445x460S1ce10460x467S2e500447x507S1ce10531x478S1ce18500x478S2fd04513x554S2df00530x504S2df14486x518
2024-02-21 14:47:25,610 - INFO - joeynmt.training - Example #3
2024-02-21 14:47:25,611 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 14:47:25,611 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 14:47:25,611 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x472S35d10487x493S10011498x496S26a04503x507S20500501x479
2024-02-21 14:48:12,869 - INFO - joeynmt.training - Epoch  14, Step:    53100, Batch Loss:     0.748470, Batch Acc: 0.712504, Tokens per Sec:      359, Lr: 0.000020
2024-02-21 14:49:02,312 - INFO - joeynmt.training - Epoch  14, Step:    53200, Batch Loss:     0.894135, Batch Acc: 0.709180, Tokens per Sec:      350, Lr: 0.000020
2024-02-21 14:49:50,782 - INFO - joeynmt.training - Epoch  14, Step:    53300, Batch Loss:     0.903184, Batch Acc: 0.714329, Tokens per Sec:      342, Lr: 0.000020
2024-02-21 14:50:38,815 - INFO - joeynmt.training - Epoch  14, Step:    53400, Batch Loss:     0.560519, Batch Acc: 0.696984, Tokens per Sec:      357, Lr: 0.000020
2024-02-21 14:51:25,592 - INFO - joeynmt.training - Epoch  14, Step:    53500, Batch Loss:     0.858450, Batch Acc: 0.708637, Tokens per Sec:      355, Lr: 0.000020
2024-02-21 14:52:13,732 - INFO - joeynmt.training - Epoch  14, Step:    53600, Batch Loss:     0.859622, Batch Acc: 0.708620, Tokens per Sec:      353, Lr: 0.000020
2024-02-21 14:53:02,941 - INFO - joeynmt.training - Epoch  14, Step:    53700, Batch Loss:     1.020076, Batch Acc: 0.712638, Tokens per Sec:      340, Lr: 0.000020
2024-02-21 14:53:50,639 - INFO - joeynmt.training - Epoch  14, Step:    53800, Batch Loss:     0.684791, Batch Acc: 0.708473, Tokens per Sec:      356, Lr: 0.000020
2024-02-21 14:54:37,388 - INFO - joeynmt.training - Epoch  14, Step:    53900, Batch Loss:     0.920096, Batch Acc: 0.705074, Tokens per Sec:      364, Lr: 0.000020
2024-02-21 14:55:25,620 - INFO - joeynmt.training - Epoch  14, Step:    54000, Batch Loss:     0.721328, Batch Acc: 0.710219, Tokens per Sec:      351, Lr: 0.000020
2024-02-21 14:55:25,620 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.15it/s]
2024-02-21 14:56:14,715 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  50.63, loss:   1.45, ppl:   4.28, acc:   0.53, generation: 48.4099[sec], evaluation: 0.6636[sec]
2024-02-21 14:56:14,717 - INFO - joeynmt.training - Example #0
2024-02-21 14:56:14,717 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 14:56:14,717 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 14:56:14,718 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d10495x454S2fb04492x561S26606503x501S26612469x501S20500495x501S18250501x483S18258479x483
2024-02-21 14:56:14,718 - INFO - joeynmt.training - Example #1
2024-02-21 14:56:14,718 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 14:56:14,718 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 14:56:14,718 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x560S20500495x493S1ea0e506x479S1ea06470x479S22b02503x498S22b16469x498
2024-02-21 14:56:14,718 - INFO - joeynmt.training - Example #2
2024-02-21 14:56:14,719 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 14:56:14,719 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 14:56:14,719 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00436x450S2ff00509x450S35d14449x470S1ce10468x471S2e500447x504S1ce10527x487S1ce18501x487S2fd04516x544S25100532x492S25114492x515
2024-02-21 14:56:14,719 - INFO - joeynmt.training - Example #3
2024-02-21 14:56:14,720 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 14:56:14,720 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 14:56:14,720 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x472S35d10487x493S10011498x496S26a04501x516
2024-02-21 14:57:02,921 - INFO - joeynmt.training - Epoch  14, Step:    54100, Batch Loss:     0.711335, Batch Acc: 0.706837, Tokens per Sec:      349, Lr: 0.000020
2024-02-21 14:57:51,859 - INFO - joeynmt.training - Epoch  14, Step:    54200, Batch Loss:     0.697299, Batch Acc: 0.705367, Tokens per Sec:      343, Lr: 0.000020
2024-02-21 14:58:40,247 - INFO - joeynmt.training - Epoch  14, Step:    54300, Batch Loss:     0.636768, Batch Acc: 0.704846, Tokens per Sec:      362, Lr: 0.000020
2024-02-21 14:59:28,634 - INFO - joeynmt.training - Epoch  14, Step:    54400, Batch Loss:     0.701662, Batch Acc: 0.709163, Tokens per Sec:      353, Lr: 0.000020
2024-02-21 15:00:16,617 - INFO - joeynmt.training - Epoch  14, Step:    54500, Batch Loss:     0.668972, Batch Acc: 0.706531, Tokens per Sec:      357, Lr: 0.000020
2024-02-21 15:01:03,688 - INFO - joeynmt.training - Epoch  14, Step:    54600, Batch Loss:     0.794699, Batch Acc: 0.707059, Tokens per Sec:      359, Lr: 0.000020
2024-02-21 15:01:52,812 - INFO - joeynmt.training - Epoch  14, Step:    54700, Batch Loss:     0.566619, Batch Acc: 0.709525, Tokens per Sec:      345, Lr: 0.000020
2024-02-21 15:02:40,955 - INFO - joeynmt.training - Epoch  14, Step:    54800, Batch Loss:     0.778814, Batch Acc: 0.713585, Tokens per Sec:      356, Lr: 0.000020
2024-02-21 15:03:28,860 - INFO - joeynmt.training - Epoch  14, Step:    54900, Batch Loss:     0.457086, Batch Acc: 0.709411, Tokens per Sec:      354, Lr: 0.000020
2024-02-21 15:04:15,697 - INFO - joeynmt.training - Epoch  14, Step:    55000, Batch Loss:     0.992518, Batch Acc: 0.708285, Tokens per Sec:      366, Lr: 0.000020
2024-02-21 15:04:15,697 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.10it/s]
2024-02-21 15:05:05,122 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  50.84, loss:   1.46, ppl:   4.29, acc:   0.53, generation: 48.7344[sec], evaluation: 0.6668[sec]
2024-02-21 15:05:05,123 - INFO - joeynmt.training - Example #0
2024-02-21 15:05:05,124 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 15:05:05,124 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 15:05:05,124 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x561S26606503x501S26612469x501S20500495x501S18250501x483S18258479x483
2024-02-21 15:05:05,124 - INFO - joeynmt.training - Example #1
2024-02-21 15:05:05,125 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 15:05:05,125 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 15:05:05,125 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S1ea0e506x478S1ea06477x478S2fd04489x560S2ea00519x497S2ea4c476x497
2024-02-21 15:05:05,125 - INFO - joeynmt.training - Example #2
2024-02-21 15:05:05,126 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 15:05:05,126 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 15:05:05,126 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00432x440S2ff00505x440S35d10445x460S1ce10460x467S2e500447x493S2fd04513x554S15020530x478S26500550x478S26510500x504S15310530x481
2024-02-21 15:05:05,126 - INFO - joeynmt.training - Example #3
2024-02-21 15:05:05,126 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 15:05:05,126 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 15:05:05,127 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x472S35d10487x493S10001498x501S21100501x473S22a06511x516
2024-02-21 15:05:54,946 - INFO - joeynmt.training - Epoch  14, Step:    55100, Batch Loss:     0.769585, Batch Acc: 0.716230, Tokens per Sec:      345, Lr: 0.000020
2024-02-21 15:06:17,215 - INFO - joeynmt.training - Epoch  14: total training loss 3123.55, num seqs 15756, num tokens 672796
2024-02-21 15:06:17,215 - INFO - joeynmt.training - EPOCH 15
2024-02-21 15:06:43,321 - INFO - joeynmt.training - Epoch  15, Step:    55200, Batch Loss:     0.437526, Batch Acc: 0.717896, Tokens per Sec:      355, Lr: 0.000020
2024-02-21 15:07:31,357 - INFO - joeynmt.training - Epoch  15, Step:    55300, Batch Loss:     0.525076, Batch Acc: 0.720756, Tokens per Sec:      353, Lr: 0.000020
2024-02-21 15:08:18,243 - INFO - joeynmt.training - Epoch  15, Step:    55400, Batch Loss:     0.672178, Batch Acc: 0.724341, Tokens per Sec:      352, Lr: 0.000020
2024-02-21 15:09:06,367 - INFO - joeynmt.training - Epoch  15, Step:    55500, Batch Loss:     0.571638, Batch Acc: 0.721342, Tokens per Sec:      341, Lr: 0.000020
2024-02-21 15:09:54,620 - INFO - joeynmt.training - Epoch  15, Step:    55600, Batch Loss:     0.665557, Batch Acc: 0.727624, Tokens per Sec:      354, Lr: 0.000020
2024-02-21 15:10:42,131 - INFO - joeynmt.training - Epoch  15, Step:    55700, Batch Loss:     0.671541, Batch Acc: 0.713661, Tokens per Sec:      366, Lr: 0.000020
2024-02-21 15:11:30,426 - INFO - joeynmt.training - Epoch  15, Step:    55800, Batch Loss:     0.946599, Batch Acc: 0.717799, Tokens per Sec:      369, Lr: 0.000020
2024-02-21 15:12:19,101 - INFO - joeynmt.training - Epoch  15, Step:    55900, Batch Loss:     1.239462, Batch Acc: 0.721756, Tokens per Sec:      360, Lr: 0.000020
2024-02-21 15:13:07,211 - INFO - joeynmt.training - Epoch  15, Step:    56000, Batch Loss:     0.935750, Batch Acc: 0.721805, Tokens per Sec:      357, Lr: 0.000020
2024-02-21 15:13:07,211 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:46<00:00,  7.45it/s]
2024-02-21 15:13:54,806 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  50.12, loss:   1.46, ppl:   4.32, acc:   0.53, generation: 46.4689[sec], evaluation: 1.0770[sec]
2024-02-21 15:13:54,808 - INFO - joeynmt.training - Example #0
2024-02-21 15:13:54,809 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 15:13:54,809 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 15:13:54,809 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x561S26606503x520S26612469x520S20500495x472S22200483x470S22200505x471S18250495x484S18258476x484
2024-02-21 15:13:54,809 - INFO - joeynmt.training - Example #1
2024-02-21 15:13:54,810 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 15:13:54,810 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 15:13:54,810 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x560S20342509x479S2034a471x479S22a04511x479S22a14480x479
2024-02-21 15:13:54,810 - INFO - joeynmt.training - Example #2
2024-02-21 15:13:54,811 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 15:13:54,811 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 15:13:54,811 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x434S2ff00501x434S35d14453x454S1ce10531x471S2e500529x501S2fd04509x560S24e38445x477S15320452x477S15328428x477S24e00458x498S24e40458x498
2024-02-21 15:13:54,811 - INFO - joeynmt.training - Example #3
2024-02-21 15:13:54,812 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 15:13:54,812 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 15:13:54,812 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x472S35d10487x493S10011498x493S21100501x493S22a06511x516
2024-02-21 15:14:42,935 - INFO - joeynmt.training - Epoch  15, Step:    56100, Batch Loss:     0.713098, Batch Acc: 0.721661, Tokens per Sec:      358, Lr: 0.000020
2024-02-21 15:15:31,476 - INFO - joeynmt.training - Epoch  15, Step:    56200, Batch Loss:     0.787598, Batch Acc: 0.719939, Tokens per Sec:      351, Lr: 0.000020
2024-02-21 15:16:20,173 - INFO - joeynmt.training - Epoch  15, Step:    56300, Batch Loss:     0.665785, Batch Acc: 0.722004, Tokens per Sec:      344, Lr: 0.000020
2024-02-21 15:17:08,585 - INFO - joeynmt.training - Epoch  15, Step:    56400, Batch Loss:     0.429649, Batch Acc: 0.717332, Tokens per Sec:      355, Lr: 0.000020
2024-02-21 15:17:56,038 - INFO - joeynmt.training - Epoch  15, Step:    56500, Batch Loss:     0.665265, Batch Acc: 0.712834, Tokens per Sec:      355, Lr: 0.000020
2024-02-21 15:18:43,960 - INFO - joeynmt.training - Epoch  15, Step:    56600, Batch Loss:     0.610884, Batch Acc: 0.712305, Tokens per Sec:      355, Lr: 0.000020
2024-02-21 15:19:32,297 - INFO - joeynmt.training - Epoch  15, Step:    56700, Batch Loss:     0.673210, Batch Acc: 0.723760, Tokens per Sec:      360, Lr: 0.000020
2024-02-21 15:20:19,677 - INFO - joeynmt.training - Epoch  15, Step:    56800, Batch Loss:     0.676718, Batch Acc: 0.712863, Tokens per Sec:      356, Lr: 0.000020
2024-02-21 15:21:06,978 - INFO - joeynmt.training - Epoch  15, Step:    56900, Batch Loss:     0.497553, Batch Acc: 0.722027, Tokens per Sec:      361, Lr: 0.000020
2024-02-21 15:21:55,033 - INFO - joeynmt.training - Epoch  15, Step:    57000, Batch Loss:     0.589578, Batch Acc: 0.727746, Tokens per Sec:      352, Lr: 0.000020
2024-02-21 15:21:55,033 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.08it/s]
2024-02-21 15:22:44,638 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  51.03, loss:   1.47, ppl:   4.33, acc:   0.53, generation: 48.8971[sec], evaluation: 0.6837[sec]
2024-02-21 15:22:44,639 - INFO - joeynmt.training - Example #0
2024-02-21 15:22:44,640 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 15:22:44,640 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 15:22:44,640 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x561S26606503x520S26612469x520S20500495x472S22200483x470S22200505x471S18250495x483S18258476x483
2024-02-21 15:22:44,640 - INFO - joeynmt.training - Example #1
2024-02-21 15:22:44,641 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 15:22:44,641 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 15:22:44,641 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S1ea0e506x478S1ea06473x478S2fb04492x560S20500495x478S22f02511x508S22f16477x508
2024-02-21 15:22:44,641 - INFO - joeynmt.training - Example #2
2024-02-21 15:22:44,642 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 15:22:44,642 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 15:22:44,642 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x434S2ff00501x434S35d14453x454S1ce10461x471S2e500448x493S2fd04509x560S14a20525x472S2e500525x494S2e518500x494
2024-02-21 15:22:44,642 - INFO - joeynmt.training - Example #3
2024-02-21 15:22:44,642 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 15:22:44,643 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 15:22:44,643 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x472S35d10487x493S10010511x475S21100501x468S22114501x493
2024-02-21 15:23:32,774 - INFO - joeynmt.training - Epoch  15, Step:    57100, Batch Loss:     0.490616, Batch Acc: 0.715572, Tokens per Sec:      355, Lr: 0.000002
2024-02-21 15:24:20,351 - INFO - joeynmt.training - Epoch  15, Step:    57200, Batch Loss:     0.607922, Batch Acc: 0.713458, Tokens per Sec:      366, Lr: 0.000002
2024-02-21 15:25:08,391 - INFO - joeynmt.training - Epoch  15, Step:    57300, Batch Loss:     1.150005, Batch Acc: 0.711829, Tokens per Sec:      354, Lr: 0.000002
2024-02-21 15:25:55,929 - INFO - joeynmt.training - Epoch  15, Step:    57400, Batch Loss:     0.800481, Batch Acc: 0.724994, Tokens per Sec:      351, Lr: 0.000002
2024-02-21 15:26:42,897 - INFO - joeynmt.training - Epoch  15, Step:    57500, Batch Loss:     0.917093, Batch Acc: 0.716971, Tokens per Sec:      368, Lr: 0.000002
2024-02-21 15:27:30,642 - INFO - joeynmt.training - Epoch  15, Step:    57600, Batch Loss:     0.504191, Batch Acc: 0.720547, Tokens per Sec:      369, Lr: 0.000002
2024-02-21 15:28:18,455 - INFO - joeynmt.training - Epoch  15, Step:    57700, Batch Loss:     0.720905, Batch Acc: 0.728779, Tokens per Sec:      353, Lr: 0.000002
2024-02-21 15:29:06,388 - INFO - joeynmt.training - Epoch  15, Step:    57800, Batch Loss:     0.978302, Batch Acc: 0.729040, Tokens per Sec:      360, Lr: 0.000002
2024-02-21 15:29:53,047 - INFO - joeynmt.training - Epoch  15, Step:    57900, Batch Loss:     0.775445, Batch Acc: 0.715139, Tokens per Sec:      366, Lr: 0.000002
2024-02-21 15:30:40,982 - INFO - joeynmt.training - Epoch  15, Step:    58000, Batch Loss:     0.520631, Batch Acc: 0.719559, Tokens per Sec:      350, Lr: 0.000002
2024-02-21 15:30:40,983 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...: 100% 346/346 [00:48<00:00,  7.18it/s]
2024-02-21 15:31:29,926 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Evaluation result (greedy) fsw_eval:  51.19, loss:   1.47, ppl:   4.34, acc:   0.53, generation: 48.2208[sec], evaluation: 0.6989[sec]
2024-02-21 15:31:30,474 - INFO - joeynmt.helpers - delete experiment/53000.ckpt
2024-02-21 15:31:30,518 - INFO - joeynmt.helpers - delete /content/signwriting-transcription/experiment/53000.ckpt
2024-02-21 15:31:30,518 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/signwriting-transcription/experiment/53000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/signwriting-transcription/experiment/53000.ckpt')
2024-02-21 15:31:30,519 - INFO - joeynmt.training - Example #0
2024-02-21 15:31:30,520 - INFO - joeynmt.training - 	Source:     fbank534.zip:317147545:333344
2024-02-21 15:31:30,520 - INFO - joeynmt.training - 	Reference:  M555x566S2ff00482x435S35d14495x455S26606525x495S26612446x495S18250501x495S18258478x495S20500495x502S2fb04493x560
2024-02-21 15:31:30,520 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x434S35d14495x454S2fb04492x561S26606503x520S26612469x520S20500495x472S22200483x470S22200501x471S20350501x502S20350484x502
2024-02-21 15:31:30,520 - INFO - joeynmt.training - Example #1
2024-02-21 15:31:30,521 - INFO - joeynmt.training - 	Source:     fbank534.zip:2124498404:408104
2024-02-21 15:31:30,521 - INFO - joeynmt.training - 	Reference:  M561x565S2ff00451x436S2ff00512x436S35c10464x456S1f512477x478S20e00478x495S1f51a446x478S20e00446x495S36d00448x472S10002531x483S1000a509x496S2fd04521x557S2ea3c510x513S2ea00545x501S22f00472x508S22f10440x509S2fc04462x554
2024-02-21 15:31:30,521 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00482x435S35d14495x455S1ea0e506x478S1ea06473x478S2fb04492x560S20500495x478S22f02511x508S22f16477x508
2024-02-21 15:31:30,521 - INFO - joeynmt.training - Example #2
2024-02-21 15:31:30,523 - INFO - joeynmt.training - 	Source:     fbank534.zip:559212597:318392
2024-02-21 15:31:30,523 - INFO - joeynmt.training - 	Reference:  M567x544S2ff00512x468S30007434x468S34410525x489S36110444x489S20500462x459S18111531x510S18119505x510S20500525x517S22100547x505S22100503x505S22a04554x529S22a14494x529S1c500466x457S2df08475x489
2024-02-21 15:31:30,524 - INFO - joeynmt.training - 	Hypothesis: M500x500S2ff00440x434S2ff00501x434S35d14453x454S1ce10461x471S2e500448x493S2fd04509x560S24e38533x500S24e40500x500S15310538x473S15318501x473
2024-02-21 15:31:30,524 - INFO - joeynmt.training - Example #3
2024-02-21 15:31:30,524 - INFO - joeynmt.training - 	Source:     fbank534.zip:174706189:378200
2024-02-21 15:31:30,524 - INFO - joeynmt.training - 	Reference:  M564x540S30006436x464S30006506x464S34410519x485S35d10449x484S10010460x478S21100469x461S22b04461x510S10000519x483S26a04537x499
2024-02-21 15:31:30,524 - INFO - joeynmt.training - 	Hypothesis: M500x500S30006474x472S35d10487x493S10010511x475S21100501x468S22114501x480
2024-02-21 15:32:18,959 - INFO - joeynmt.training - Epoch  15, Step:    58100, Batch Loss:     0.768042, Batch Acc: 0.727984, Tokens per Sec:      352, Lr: 0.000002
2024-02-21 15:33:06,022 - INFO - joeynmt.training - Epoch  15, Step:    58200, Batch Loss:     0.990891, Batch Acc: 0.715332, Tokens per Sec:      374, Lr: 0.000002
2024-02-21 15:33:53,849 - INFO - joeynmt.training - Epoch  15, Step:    58300, Batch Loss:     0.580505, Batch Acc: 0.721260, Tokens per Sec:      355, Lr: 0.000002
2024-02-21 15:34:41,675 - INFO - joeynmt.training - Epoch  15, Step:    58400, Batch Loss:     0.801024, Batch Acc: 0.720364, Tokens per Sec:      356, Lr: 0.000002
2024-02-21 15:35:29,471 - INFO - joeynmt.training - Epoch  15, Step:    58500, Batch Loss:     0.674335, Batch Acc: 0.720126, Tokens per Sec:      364, Lr: 0.000002
2024-02-21 15:36:16,571 - INFO - joeynmt.training - Epoch  15, Step:    58600, Batch Loss:     0.890647, Batch Acc: 0.726453, Tokens per Sec:      365, Lr: 0.000002
2024-02-21 15:37:04,420 - INFO - joeynmt.training - Epoch  15, Step:    58700, Batch Loss:     0.577057, Batch Acc: 0.722636, Tokens per Sec:      351, Lr: 0.000002
2024-02-21 15:37:52,091 - INFO - joeynmt.training - Epoch  15, Step:    58800, Batch Loss:     0.927059, Batch Acc: 0.717538, Tokens per Sec:      363, Lr: 0.000002
2024-02-21 15:38:39,028 - INFO - joeynmt.training - Epoch  15, Step:    58900, Batch Loss:     0.556881, Batch Acc: 0.721773, Tokens per Sec:      358, Lr: 0.000002
2024-02-21 15:39:26,711 - INFO - joeynmt.training - Epoch  15, Step:    59000, Batch Loss:     0.775360, Batch Acc: 0.726815, Tokens per Sec:      350, Lr: 0.000002
2024-02-21 15:39:26,712 - INFO - signwriting_transcription.pose_to_signwriting.joeynmt_pose.prediction - Predicting 346 example(s)... (Greedy decoding with min_output_length=1, max_output_length=100, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:  77% 268/346 [00:39<00:10,  7.10it/s]